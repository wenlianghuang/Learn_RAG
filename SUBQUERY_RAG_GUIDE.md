# Sub-query Decomposition RAG å®Œæ•´ä½¿ç”¨æŒ‡å—

## ğŸ“‹ ç›®éŒ„

1. [æ¦‚è¿°](#æ¦‚è¿°)
2. [å·¥ä½œåŸç†](#å·¥ä½œåŸç†)
3. [å¿«é€Ÿé–‹å§‹](#å¿«é€Ÿé–‹å§‹)
4. [è©³ç´°åƒæ•¸èªªæ˜](#è©³ç´°åƒæ•¸èªªæ˜)
5. [API åƒè€ƒ](#api-åƒè€ƒ)
6. [ä½¿ç”¨å ´æ™¯èˆ‡ç¤ºä¾‹](#ä½¿ç”¨å ´æ™¯èˆ‡ç¤ºä¾‹)
7. [æ€§èƒ½å„ªåŒ–](#æ€§èƒ½å„ªåŒ–)
8. [æœ€ä½³å¯¦è¸](#æœ€ä½³å¯¦è¸)
9. [èˆ‡æ­£å¸¸ RAG çš„å°æ¯”](#èˆ‡æ­£å¸¸-rag-çš„å°æ¯”)
10. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)
11. [å¸¸è¦‹å•é¡Œ](#å¸¸è¦‹å•é¡Œ)
12. [æ¸¬è©¦èˆ‡é©—è­‰](#æ¸¬è©¦èˆ‡é©—è­‰)

---

## ğŸ“– æ¦‚è¿°

### ä»€éº¼æ˜¯ Sub-query Decomposition RAGï¼Ÿ

Sub-query Decomposition RAGï¼ˆå­å•é¡Œæ‹†è§£ RAGï¼‰æ˜¯ä¸€ç¨®é€²éšçš„ RAGï¼ˆRetrieval-Augmented Generationï¼‰æŠ€è¡“ï¼Œå®ƒé€šéå°‡è¤‡é›œå•é¡Œæ‹†è§£æˆå¤šå€‹å­å•é¡Œä¾†æå‡æª¢ç´¢å’Œç”Ÿæˆè³ªé‡ã€‚

### æ ¸å¿ƒæ€æƒ³

ç•¶ç”¨æˆ¶æå‡ºä¸€å€‹è¤‡é›œçš„ã€åŒ…å«å¤šå€‹é¢å‘çš„å•é¡Œæ™‚ï¼Œå–®ä¸€çš„æª¢ç´¢æŸ¥è©¢å¯èƒ½ç„¡æ³•å…¨é¢è¦†è“‹æ‰€æœ‰ç›¸é—œè³‡è¨Šã€‚Sub-query Decomposition RAG çš„è§£æ±ºæ–¹æ¡ˆæ˜¯ï¼š

1. **å•é¡Œæ‹†è§£**ï¼šä½¿ç”¨ LLM å°‡åŸå§‹å•é¡Œæ‹†è§£æˆå¤šå€‹å°ˆæ³¨æ–¼ç‰¹å®šé¢å‘çš„å­å•é¡Œ
2. **ä¸¦è¡Œæª¢ç´¢**ï¼šå°æ¯å€‹å­å•é¡Œåˆ†åˆ¥é€²è¡Œæª¢ç´¢ï¼Œç²å–ç›¸é—œæ–‡æª”
3. **çµæœåˆä½µ**ï¼šå°‡æ‰€æœ‰å­å•é¡Œçš„æª¢ç´¢çµæœåˆä½µï¼Œå»é™¤é‡è¤‡ï¼Œä¿ç•™æœ€ç›¸é—œçš„æ–‡æª”
4. **ç­”æ¡ˆç”Ÿæˆ**ï¼šåŸºæ–¼åˆä½µå¾Œçš„æ–‡æª”ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ

### é©ç”¨å ´æ™¯

âœ… **é©åˆä½¿ç”¨ Sub-query Decomposition RAG çš„æƒ…æ³ï¼š**
- è¤‡é›œçš„æ¯”è¼ƒå•é¡Œï¼ˆå¦‚ã€Œæ¯”è¼ƒ A å’Œ B çš„å·®ç•°ã€å„ªç¼ºé»å’Œæ‡‰ç”¨å ´æ™¯ã€ï¼‰
- å¤šé¢å‘æŸ¥è©¢ï¼ˆå¦‚ã€Œtransformer architecture, attention mechanism, and optimizationã€ï¼‰
- ç¶œåˆæ€§å•é¡Œï¼ˆå¦‚ã€Œäº¬éƒ½èˆ‡å¤§é˜ªçš„è³æ¥“äº¤é€šèˆ‡æ“æ“ åº¦æ¯”è¼ƒã€ï¼‰
- éœ€è¦å¾å¤šå€‹è§’åº¦æª¢ç´¢è³‡è¨Šçš„å•é¡Œ

âŒ **ä¸é©åˆä½¿ç”¨çš„æƒ…æ³ï¼š**
- ç°¡å–®çš„å–®ä¸€å•é¡Œï¼ˆå¦‚ã€Œä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿã€ï¼‰
- äº‹å¯¦æ€§æŸ¥è©¢ï¼ˆå¦‚ã€ŒPython çš„å‰µå»ºå¹´ä»½ã€ï¼‰
- å°éŸ¿æ‡‰æ™‚é–“è¦æ±‚æ¥µé«˜çš„å ´æ™¯

---

## ğŸ”§ å·¥ä½œåŸç†

### å·¥ä½œæµç¨‹åœ–

```
åŸå§‹å•é¡Œ
    â†“
[LLM å­å•é¡Œç”Ÿæˆ]
    â†“
å­å•é¡Œ 1 â”€â”€â”
å­å•é¡Œ 2 â”€â”€â”¤
å­å•é¡Œ 3 â”€â”€â”˜
    â†“
[ä¸¦è¡Œ/ä¸²è¡Œæª¢ç´¢]
    â†“
æª¢ç´¢çµæœ 1 â”€â”€â”
æª¢ç´¢çµæœ 2 â”€â”€â”¤
æª¢ç´¢çµæœ 3 â”€â”€â”˜
    â†“
[å»é‡èˆ‡åˆä½µ]
    â†“
æœ€çµ‚æ–‡æª”åˆ—è¡¨
    â†“
[ç­”æ¡ˆç”Ÿæˆ]
    â†“
æœ€çµ‚ç­”æ¡ˆ
```

### è©³ç´°æ­¥é©Ÿèªªæ˜

#### æ­¥é©Ÿ 1: å­å•é¡Œç”Ÿæˆ

ä½¿ç”¨ LLM å°‡åŸå§‹å•é¡Œæ‹†è§£æˆå­å•é¡Œï¼š

```python
åŸå§‹å•é¡Œ: "æ¯”è¼ƒæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°ã€å„ªç¼ºé»å’Œæ‡‰ç”¨å ´æ™¯"

ç”Ÿæˆçš„å­å•é¡Œ:
1. æ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°æ˜¯ä»€éº¼ï¼Ÿ
2. æ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’å„è‡ªçš„å„ªç¼ºé»æ˜¯ä»€éº¼ï¼Ÿ
3. æ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„æ‡‰ç”¨å ´æ™¯æœ‰å“ªäº›ï¼Ÿ
```

**æŠ€è¡“ç´°ç¯€ï¼š**
- ä½¿ç”¨ `temperature=0.3` ä»¥ç²å¾—æ›´ç©©å®šçš„çµæœ
- è‡ªå‹•æª¢æ¸¬å•é¡Œèªè¨€ï¼ˆä¸­æ–‡/è‹±æ–‡ï¼‰
- è‡ªå‹•æ¸…ç†ç·¨è™Ÿå‰ç¶´ï¼ˆå¦‚ "1. ", "1) "ï¼‰
- å¦‚æœç”Ÿæˆå¤±æ•—ï¼Œå›é€€åˆ°ä½¿ç”¨åŸå§‹å•é¡Œ

#### æ­¥é©Ÿ 2: ä¸¦è¡Œ/ä¸²è¡Œæª¢ç´¢

å°æ¯å€‹å­å•é¡Œé€²è¡Œæª¢ç´¢ï¼š

**ä¸¦è¡Œæ¨¡å¼ï¼ˆæ¨è–¦ï¼‰ï¼š**
- ä½¿ç”¨ `ThreadPoolExecutor` ä¸¦è¡Œè™•ç†
- æœ€å¤š 5 å€‹ä¸¦ç™¼ç·šç¨‹
- é©åˆå¤šå€‹å­å•é¡Œçš„æƒ…æ³

**ä¸²è¡Œæ¨¡å¼ï¼š**
- é †åºè™•ç†æ¯å€‹å­å•é¡Œ
- é©åˆå–®å€‹å­å•é¡Œæˆ–èª¿è©¦å ´æ™¯

#### æ­¥é©Ÿ 3: å»é‡èˆ‡åˆä½µ

**å»é‡ç­–ç•¥ï¼š**
1. å„ªå…ˆä½¿ç”¨ metadata ä¸­çš„å”¯ä¸€æ¨™è­˜ï¼š
   - `arxiv_id + chunk_index`ï¼ˆè«–æ–‡ï¼‰
   - `file_path + chunk_index`ï¼ˆæª”æ¡ˆï¼‰
2. å›é€€åˆ°å…§å®¹ hashï¼ˆMD5 å‰ 16 ä½ï¼‰

**åˆ†æ•¸ä¿ç•™ï¼š**
- å¦‚æœåŒä¸€æ–‡æª”åœ¨å¤šå€‹å­å•é¡Œçš„çµæœä¸­å‡ºç¾ï¼Œä¿ç•™åˆ†æ•¸æ›´é«˜çš„ç‰ˆæœ¬
- åˆ†æ•¸å„ªå…ˆç´šï¼š`rerank_score` > `hybrid_score` > `score`

#### æ­¥é©Ÿ 4: æ’åºèˆ‡ç¯©é¸

- æŒ‰åˆ†æ•¸å¾é«˜åˆ°ä½æ’åº
- è¿”å›å‰ `top_k` å€‹çµæœ

---

## ğŸš€ å¿«é€Ÿé–‹å§‹

### å‰ç½®æ¢ä»¶

1. **å®‰è£ä¾è³´**ï¼š
```bash
# ç¢ºä¿å·²å®‰è£æ‰€æœ‰å¿…è¦çš„ä¾è³´
pip install -r requirements.txt
# æˆ–ä½¿ç”¨ uv
uv sync
```

2. **å•Ÿå‹• Ollama**ï¼š
```bash
# ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œ
ollama serve

# ä¸‹è¼‰æ¨¡å‹ï¼ˆå¦‚æœé‚„æ²’æœ‰ï¼‰
ollama pull llama3.2:3b
```

### åŸºæœ¬ä½¿ç”¨ç¤ºä¾‹

#### ç¤ºä¾‹ 1: å®Œæ•´æµç¨‹ï¼ˆæª¢ç´¢ + ç”Ÿæˆç­”æ¡ˆï¼‰

```python
from src import (
    DocumentProcessor, BM25Retriever, VectorRetriever,
    HybridSearch, Reranker, RAGPipeline,
    PromptFormatter, OllamaLLM, SubQueryDecompositionRAG
)

# 1. åˆå§‹åŒ–åŸºç¤ RAG ç³»çµ±
processor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)
documents = processor.process_documents(papers)  # æˆ– process_file()

bm25_retriever = BM25Retriever(documents)
vector_retriever = VectorRetriever(
    documents, 
    embedding_model="sentence-transformers/all-MiniLM-L6-v2",
    persist_directory="./chroma_db"
)
hybrid_search = HybridSearch(bm25_retriever, vector_retriever)

reranker = Reranker()
rag_pipeline = RAGPipeline(hybrid_search, reranker)

# 2. åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨
llm = OllamaLLM(model_name="llama3.2:3b", timeout=180)
formatter = PromptFormatter(
    include_metadata=True,
    format_style="detailed"
)

# 3. åˆå§‹åŒ– Sub-query Decomposition RAG
subquery_rag = SubQueryDecompositionRAG(
    rag_pipeline=rag_pipeline,
    llm=llm,
    max_sub_queries=3,          # æœ€å¤šç”Ÿæˆ 3 å€‹å­å•é¡Œ
    top_k_per_subquery=5,      # æ¯å€‹å­å•é¡Œæª¢ç´¢ 5 å€‹çµæœ
    enable_parallel=True        # å•Ÿç”¨ä¸¦è¡Œè™•ç†
)

# 4. åŸ·è¡ŒæŸ¥è©¢
question = "æ¯”è¼ƒäº¬éƒ½èˆ‡å¤§é˜ªçš„è³æ¥“äº¤é€šèˆ‡æ“æ“ åº¦"
result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    top_k=5,
    document_type="general",
    return_sub_queries=True
)

# 5. æŸ¥çœ‹çµæœ
print(f"ç”Ÿæˆçš„å­å•é¡Œ: {result['sub_queries']}")
print(f"æ‰¾åˆ°çš„æ–‡æª”æ•¸: {result['total_docs_found']}")
print(f"ç¸½è€—æ™‚: {result['total_time']:.2f}s")
print(f"ç”Ÿæˆçš„å›ç­”:\n{result['answer']}")
```

#### ç¤ºä¾‹ 2: åƒ…æª¢ç´¢ï¼ˆä¸ç”Ÿæˆç­”æ¡ˆï¼‰

```python
# åªé€²è¡Œæª¢ç´¢ï¼Œä¸ç”Ÿæˆæœ€çµ‚ç­”æ¡ˆ
result = subquery_rag.query(
    question="transformer architecture and attention mechanism",
    top_k=5,
    return_sub_queries=True
)

# æŸ¥çœ‹æª¢ç´¢çµæœ
print(f"ç”Ÿæˆçš„å­å•é¡Œ ({len(result['sub_queries'])} å€‹):")
for i, sq in enumerate(result['sub_queries'], 1):
    print(f"  {i}. {sq}")

print(f"\næª¢ç´¢åˆ°çš„æ–‡æª” ({len(result['results'])} å€‹):")
for i, doc in enumerate(result['results'], 1):
    print(f"\n  {i}. {doc['metadata'].get('title', 'N/A')}")
    print(f"     åˆ†æ•¸: {doc.get('rerank_score', doc.get('hybrid_score', 0)):.4f}")
    print(f"     å…§å®¹é è¦½: {doc['content'][:150]}...")
```

---

## âš™ï¸ è©³ç´°åƒæ•¸èªªæ˜

### SubQueryDecompositionRAG åˆå§‹åŒ–åƒæ•¸

#### `rag_pipeline` (RAGPipeline, å¿…éœ€)

**èªªæ˜ï¼š** ç¾æœ‰çš„ RAG ç®¡ç·šå¯¦ä¾‹ï¼Œç”¨æ–¼åŸ·è¡Œå¯¦éš›çš„æª¢ç´¢æ“ä½œã€‚

**è¦æ±‚ï¼š**
- å¿…é ˆæ˜¯å·²åˆå§‹åŒ–çš„ `RAGPipeline` å¯¦ä¾‹
- æ‡‰è©²åŒ…å«é…ç½®å¥½çš„ `HybridSearch` å’Œ `Reranker`

**ç¤ºä¾‹ï¼š**
```python
rag_pipeline = RAGPipeline(
    hybrid_search=hybrid_search,
    reranker=reranker,
    recall_k=25,
    adaptive_recall=True
)
```

#### `llm` (OllamaLLM, å¿…éœ€)

**èªªæ˜ï¼š** LLM å¯¦ä¾‹ï¼Œç”¨æ–¼ç”Ÿæˆå­å•é¡Œã€‚

**è¦æ±‚ï¼š**
- å¿…é ˆæ˜¯å·²åˆå§‹åŒ–çš„ `OllamaLLM` å¯¦ä¾‹
- ç¢ºä¿ Ollama æœå‹™æ­£åœ¨é‹è¡Œ
- å»ºè­°ä½¿ç”¨è‡³å°‘ 3B åƒæ•¸ä»¥ä¸Šçš„æ¨¡å‹ä»¥ç²å¾—æ›´å¥½çš„å­å•é¡Œè³ªé‡

**æ¨è–¦æ¨¡å‹ï¼š**
- `llama3.2:3b` - å¹³è¡¡æ€§èƒ½å’Œè³ªé‡ï¼ˆæ¨è–¦ï¼‰
- `llama3.2:1b` - å¿«é€Ÿä½†è³ªé‡è¼ƒä½
- `deepseek-r1:7b` - é«˜è³ªé‡ä½†éœ€è¦æ›´å¤šå…§å­˜

**ç¤ºä¾‹ï¼š**
```python
llm = OllamaLLM(
    model_name="llama3.2:3b",
    timeout=180  # è¶…æ™‚æ™‚é–“ï¼ˆç§’ï¼‰
)
```

#### `max_sub_queries` (int, é è¨­=3)

**èªªæ˜ï¼š** æœ€å¤šç”Ÿæˆçš„å­å•é¡Œæ•¸é‡ã€‚

**ç¯„åœï¼š** 1-10ï¼ˆå»ºè­° 2-5ï¼‰

**å½±éŸ¿ï¼š**
- **è¼ƒå°å€¼ï¼ˆ1-2ï¼‰**ï¼šé©åˆç°¡å–®å•é¡Œï¼ŒéŸ¿æ‡‰æ›´å¿«
- **ä¸­ç­‰å€¼ï¼ˆ3-4ï¼‰**ï¼šé©åˆå¤§å¤šæ•¸è¤‡é›œå•é¡Œï¼ˆæ¨è–¦ï¼‰
- **è¼ƒå¤§å€¼ï¼ˆ5-10ï¼‰**ï¼šé©åˆæ¥µå…¶è¤‡é›œçš„å•é¡Œï¼Œä½†æœƒå¢åŠ æª¢ç´¢æ™‚é–“

**é¸æ“‡å»ºè­°ï¼š**
- ç°¡å–®å•é¡Œï¼š1-2
- ä¸­ç­‰è¤‡é›œåº¦ï¼š2-3
- è¤‡é›œå•é¡Œï¼š3-5
- æ¥µå…¶è¤‡é›œï¼š5-7

**ç¤ºä¾‹ï¼š**
```python
# å°æ–¼ç°¡å–®å•é¡Œ
subquery_rag = SubQueryDecompositionRAG(
    ..., max_sub_queries=2
)

# å°æ–¼è¤‡é›œå•é¡Œ
subquery_rag = SubQueryDecompositionRAG(
    ..., max_sub_queries=5
)
```

#### `top_k_per_subquery` (int, é è¨­=5)

**èªªæ˜ï¼š** æ¯å€‹å­å•é¡Œæª¢ç´¢çš„çµæœæ•¸é‡ã€‚

**ç¯„åœï¼š** 1-50ï¼ˆå»ºè­° 3-20ï¼‰

**å½±éŸ¿ï¼š**
- **è¼ƒå°å€¼ï¼ˆ3-5ï¼‰**ï¼šæª¢ç´¢æ›´å¿«ï¼Œä½†å¯èƒ½éºæ¼ç›¸é—œæ–‡æª”
- **ä¸­ç­‰å€¼ï¼ˆ5-10ï¼‰**ï¼šå¹³è¡¡è¦†è“‹ç‡å’Œæ€§èƒ½ï¼ˆæ¨è–¦ï¼‰
- **è¼ƒå¤§å€¼ï¼ˆ10-20ï¼‰**ï¼šæ›´å…¨é¢çš„è¦†è“‹ï¼Œä½†æª¢ç´¢æ™‚é–“æ›´é•·

**é¸æ“‡å»ºè­°ï¼ˆæ ¹æ“šæ–‡æª”åº«å¤§å°ï¼‰ï¼š**
- å°æ–‡æª”åº«ï¼ˆ<1000 chunksï¼‰ï¼š3-5
- ä¸­æ–‡æª”åº«ï¼ˆ1000-10000 chunksï¼‰ï¼š5-10
- å¤§æ–‡æª”åº«ï¼ˆ>10000 chunksï¼‰ï¼š10-20

**æ³¨æ„ï¼š** æœ€çµ‚è¿”å›çš„çµæœæ•¸é‡ç”± `query()` æˆ– `generate_answer()` çš„ `top_k` åƒæ•¸æ±ºå®šã€‚

**ç¤ºä¾‹ï¼š**
```python
# å°æ–‡æª”åº«
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=3
)

# å¤§æ–‡æª”åº«
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=15
)
```

#### `enable_parallel` (bool, é è¨­=True)

**èªªæ˜ï¼š** æ˜¯å¦ä¸¦è¡Œè™•ç†å­æŸ¥è©¢ã€‚

**å½±éŸ¿ï¼š**
- **Trueï¼ˆä¸¦è¡Œï¼‰**ï¼šå¤šå€‹å­å•é¡ŒåŒæ™‚æª¢ç´¢ï¼Œç¸½æ™‚é–“ç´„ç­‰æ–¼æœ€æ…¢çš„å­æŸ¥è©¢æ™‚é–“
- **Falseï¼ˆä¸²è¡Œï¼‰**ï¼šé †åºè™•ç†æ¯å€‹å­å•é¡Œï¼Œç¸½æ™‚é–“ç­‰æ–¼æ‰€æœ‰å­æŸ¥è©¢æ™‚é–“ä¹‹å’Œ

**æ€§èƒ½å°æ¯”ï¼š**
- 3 å€‹å­å•é¡Œï¼Œæ¯å€‹è€—æ™‚ 2 ç§’ï¼š
  - ä¸¦è¡Œï¼šç´„ 2 ç§’
  - ä¸²è¡Œï¼šç´„ 6 ç§’

**å»ºè­°ï¼š**
- å¤šå€‹å­å•é¡Œï¼ˆâ‰¥2ï¼‰ï¼šä½¿ç”¨ä¸¦è¡Œï¼ˆ`True`ï¼‰
- å–®å€‹å­å•é¡Œæˆ–èª¿è©¦ï¼šä½¿ç”¨ä¸²è¡Œï¼ˆ`False`ï¼‰

**ç¤ºä¾‹ï¼š**
```python
# ç”Ÿç”¢ç’°å¢ƒï¼ˆæ¨è–¦ï¼‰
subquery_rag = SubQueryDecompositionRAG(
    ..., enable_parallel=True
)

# èª¿è©¦æ¨¡å¼
subquery_rag = SubQueryDecompositionRAG(
    ..., enable_parallel=False
)
```

### query() æ–¹æ³•åƒæ•¸

#### `question` (str, å¿…éœ€)

**èªªæ˜ï¼š** åŸå§‹å•é¡Œæ–‡æœ¬ã€‚

**è¦æ±‚ï¼š**
- éç©ºå­—ç¬¦ä¸²
- æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡
- å»ºè­°å•é¡Œé•·åº¦ï¼š10-500 å­—ç¬¦

**ç¤ºä¾‹ï¼š**
```python
question = "æ¯”è¼ƒæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°ã€å„ªç¼ºé»å’Œæ‡‰ç”¨å ´æ™¯"
```

#### `top_k` (int, é è¨­=5)

**èªªæ˜ï¼š** è¿”å›å‰ k å€‹çµæœã€‚

**ç¯„åœï¼š** 1-50ï¼ˆå»ºè­° 3-10ï¼‰

**æ³¨æ„ï¼š** é€™æ˜¯æœ€çµ‚è¿”å›çš„çµæœæ•¸é‡ï¼Œå¯èƒ½å°æ–¼ `total_docs_found`ï¼ˆå»é‡å¾Œçš„ç¸½æ–‡æª”æ•¸ï¼‰ã€‚

#### `metadata_filter` (Dict, å¯é¸)

**èªªæ˜ï¼š** metadata éæ¿¾æ¢ä»¶ï¼Œç”¨æ–¼é™åˆ¶æª¢ç´¢ç¯„åœã€‚

**æ ¼å¼ï¼š**
```python
{
    "arxiv_id": "1234.5678",  # åªæª¢ç´¢ç‰¹å®šè«–æ–‡
    "title": "Machine Learning",  # æ¨™é¡ŒåŒ…å«é—œéµè©
    "file_path": "/path/to/file.pdf"  # ç‰¹å®šæª”æ¡ˆ
}
```

**é‚è¼¯ï¼š** æ‰€æœ‰æ¢ä»¶å¿…é ˆåŒæ™‚æ»¿è¶³ï¼ˆAND é‚è¼¯ï¼‰

**ç¤ºä¾‹ï¼š**
```python
# åªæª¢ç´¢ç‰¹å®šè«–æ–‡çš„ chunks
result = subquery_rag.query(
    question="transformer architecture",
    metadata_filter={"arxiv_id": "1706.03762"}
)
```

#### `return_sub_queries` (bool, é è¨­=False)

**èªªæ˜ï¼š** æ˜¯å¦åœ¨çµæœä¸­åŒ…å«å­å•é¡Œåˆ—è¡¨ã€‚

**ç”¨é€”ï¼š**
- èª¿è©¦ï¼šæŸ¥çœ‹ç”Ÿæˆçš„å­å•é¡Œ
- åˆ†æï¼šäº†è§£å•é¡Œæ‹†è§£æ•ˆæœ
- æ—¥èªŒï¼šè¨˜éŒ„å­å•é¡Œç”¨æ–¼å¾ŒçºŒåˆ†æ

### generate_answer() æ–¹æ³•åƒæ•¸

#### `question` (str, å¿…éœ€)

åŒ `query()` æ–¹æ³•çš„ `question` åƒæ•¸ã€‚

#### `formatter` (PromptFormatter, å¿…éœ€)

**èªªæ˜ï¼š** Prompt æ ¼å¼åŒ–å™¨ï¼Œç”¨æ–¼æ ¼å¼åŒ–æª¢ç´¢çµæœå’Œå‰µå»ºæœ€çµ‚ promptã€‚

**è¦æ±‚ï¼š** å¿…é ˆæ˜¯å·²åˆå§‹åŒ–çš„ `PromptFormatter` å¯¦ä¾‹ã€‚

**ç¤ºä¾‹ï¼š**
```python
formatter = PromptFormatter(
    include_metadata=True,
    format_style="detailed"
)
```

#### `top_k` (int, é è¨­=5)

**èªªæ˜ï¼š** ç”¨æ–¼ç”Ÿæˆç­”æ¡ˆçš„æ–‡æª”æ•¸é‡ã€‚

**å»ºè­°ï¼š**
- ç°¡å–®å•é¡Œï¼š3-5
- è¤‡é›œå•é¡Œï¼š5-10
- æ¥µå…¶è¤‡é›œï¼š10-15

**æ³¨æ„ï¼š** éå¤šçš„æ–‡æª”å¯èƒ½å°è‡´ prompt éé•·ï¼Œå½±éŸ¿ç”Ÿæˆè³ªé‡ã€‚

#### `metadata_filter` (Dict, å¯é¸)

åŒ `query()` æ–¹æ³•çš„ `metadata_filter` åƒæ•¸ã€‚

#### `document_type` (str, é è¨­="general")

**èªªæ˜ï¼š** æ–‡æª”é¡å‹ï¼Œç”¨æ–¼èª¿æ•´ prompt æ ¼å¼ã€‚

**é¸é …ï¼š**
- `"paper"` - å­¸è¡“è«–æ–‡ï¼ˆæœƒåŒ…å« arXiv IDã€ä½œè€…ç­‰è³‡è¨Šï¼‰
- `"cv"` - ç°¡æ­·/å±¥æ­·ï¼ˆæœƒåŒ…å«æª”æ¡ˆè·¯å¾‘ç­‰è³‡è¨Šï¼‰
- `"general"` - é€šç”¨æ–‡æª”ï¼ˆé è¨­ï¼‰

**ç¤ºä¾‹ï¼š**
```python
# è™•ç†è«–æ–‡
result = subquery_rag.generate_answer(
    question="transformer architecture",
    formatter=formatter,
    document_type="paper"
)

# è™•ç†ç°¡æ­·
result = subquery_rag.generate_answer(
    question="é€™å€‹äººçš„å·¥ä½œç¶“é©—",
    formatter=formatter,
    document_type="cv"
)
```

#### `return_sub_queries` (bool, é è¨­=False)

åŒ `query()` æ–¹æ³•çš„ `return_sub_queries` åƒæ•¸ã€‚

---

## ğŸ“š API åƒè€ƒ

### é¡ï¼šSubQueryDecompositionRAG

#### æ–¹æ³•ï¼š`__init__()`

åˆå§‹åŒ– Sub-query Decomposition RAG å¯¦ä¾‹ã€‚

**ç°½åï¼š**
```python
def __init__(
    self,
    rag_pipeline: RAGPipeline,
    llm: OllamaLLM,
    max_sub_queries: int = 3,
    top_k_per_subquery: int = 5,
    enable_parallel: bool = True
) -> None
```

#### æ–¹æ³•ï¼š`query()`

åŸ·è¡Œ Sub-query Decomposition æª¢ç´¢ï¼ˆä¸ç”Ÿæˆç­”æ¡ˆï¼‰ã€‚

**ç°½åï¼š**
```python
def query(
    self,
    question: str,
    top_k: int = 5,
    metadata_filter: Optional[Dict] = None,
    return_sub_queries: bool = False
) -> Dict
```

**è¿”å›ï¼š**
```python
{
    "results": List[Dict],           # æª¢ç´¢çµæœåˆ—è¡¨ï¼Œæ¯å€‹åŒ…å«ï¼š
                                     #   - content: str
                                     #   - metadata: Dict
                                     #   - rerank_score: float (å¦‚æœæœ‰)
                                     #   - hybrid_score: float (å¦‚æœæœ‰)
    "total_docs_found": int,         # å»é‡å¾Œçš„ç¸½æ–‡æª”æ•¸
    "sub_queries": List[str],        # å­å•é¡Œåˆ—è¡¨ï¼ˆå¦‚æœ return_sub_queries=Trueï¼‰
    "elapsed_time": float            # æª¢ç´¢è€—æ™‚ï¼ˆç§’ï¼‰
}
```

**ç•°å¸¸ï¼š**
- `ConnectionError`: LLM é€£æ¥å¤±æ•—
- `TimeoutError`: æª¢ç´¢è¶…æ™‚
- `ValueError`: åƒæ•¸ç„¡æ•ˆ

#### æ–¹æ³•ï¼š`generate_answer()`

åŸ·è¡Œå®Œæ•´çš„ Sub-query Decomposition RAG æµç¨‹ï¼ˆæª¢ç´¢ + ç”Ÿæˆç­”æ¡ˆï¼‰ã€‚

**ç°½åï¼š**
```python
def generate_answer(
    self,
    question: str,
    formatter: PromptFormatter,
    top_k: int = 5,
    metadata_filter: Optional[Dict] = None,
    document_type: str = "general",
    return_sub_queries: bool = False
) -> Dict
```

**è¿”å›ï¼š**
```python
{
    "results": List[Dict],           # æª¢ç´¢çµæœåˆ—è¡¨
    "total_docs_found": int,         # å»é‡å¾Œçš„ç¸½æ–‡æª”æ•¸
    "sub_queries": List[str],        # å­å•é¡Œåˆ—è¡¨ï¼ˆå¦‚æœ return_sub_queries=Trueï¼‰
    "elapsed_time": float,           # æª¢ç´¢è€—æ™‚ï¼ˆç§’ï¼‰
    "answer": str,                   # ç”Ÿæˆçš„å›ç­”
    "formatted_context": str,        # æ ¼å¼åŒ–å¾Œçš„ä¸Šä¸‹æ–‡
    "answer_time": float,            # ç”Ÿæˆç­”æ¡ˆè€—æ™‚ï¼ˆç§’ï¼‰
    "total_time": float              # ç¸½è€—æ™‚ï¼ˆç§’ï¼‰
}
```

**ç•°å¸¸ï¼š**
- `ConnectionError`: LLM é€£æ¥å¤±æ•—
- `TimeoutError`: æª¢ç´¢æˆ–ç”Ÿæˆè¶…æ™‚
- `ValueError`: åƒæ•¸ç„¡æ•ˆ

---

## ğŸ” ä½¿ç”¨å ´æ™¯èˆ‡ç¤ºä¾‹

### å ´æ™¯ 1: è¤‡é›œæ¯”è¼ƒå•é¡Œ

**å•é¡Œç‰¹å¾µï¼š** éœ€è¦æ¯”è¼ƒå¤šå€‹å¯¦é«”çš„å¤šå€‹æ–¹é¢

**ç¤ºä¾‹ï¼š**
```python
question = "æ¯”è¼ƒæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°ã€å„ªç¼ºé»å’Œæ‡‰ç”¨å ´æ™¯"

# é æœŸç”Ÿæˆçš„å­å•é¡Œï¼š
# 1. æ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°æ˜¯ä»€éº¼ï¼Ÿ
# 2. æ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’å„è‡ªçš„å„ªç¼ºé»æ˜¯ä»€éº¼ï¼Ÿ
# 3. æ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„æ‡‰ç”¨å ´æ™¯æœ‰å“ªäº›ï¼Ÿ

result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    top_k=5,
    document_type="paper"
)
```

**å„ªå‹¢ï¼š** æ¯å€‹å­å•é¡Œå°ˆæ³¨æ–¼ä¸€å€‹ç‰¹å®šé¢å‘ï¼Œæª¢ç´¢çµæœæ›´ç²¾ç¢ºã€‚

### å ´æ™¯ 2: å¤šé¢å‘æŠ€è¡“æŸ¥è©¢

**å•é¡Œç‰¹å¾µï¼š** åŒ…å«å¤šå€‹æŠ€è¡“æ¦‚å¿µæˆ–ä¸»é¡Œ

**ç¤ºä¾‹ï¼š**
```python
question = "transformer architecture, attention mechanism, and optimization techniques"

# é æœŸç”Ÿæˆçš„å­å•é¡Œï¼š
# 1. What is transformer architecture?
# 2. How does attention mechanism work?
# 3. What are the optimization techniques for transformers?

result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    top_k=5,
    document_type="paper"
)
```

**å„ªå‹¢ï¼š** åˆ†åˆ¥æª¢ç´¢æ¯å€‹æ¦‚å¿µï¼Œé¿å…å–®ä¸€æŸ¥è©¢å¯èƒ½éºæ¼çš„è³‡è¨Šã€‚

### å ´æ™¯ 3: ç¶œåˆæ€§æ—…éŠæŸ¥è©¢

**å•é¡Œç‰¹å¾µï¼š** æ¶‰åŠå¤šå€‹åœ°é»ã€å¤šå€‹æ–¹é¢çš„æ¯”è¼ƒ

**ç¤ºä¾‹ï¼š**
```python
question = "äº¬éƒ½èˆ‡å¤§é˜ªçš„è³æ¥“äº¤é€šèˆ‡æ“æ“ åº¦æ¯”è¼ƒ"

# é æœŸç”Ÿæˆçš„å­å•é¡Œï¼š
# 1. äº¬éƒ½è³æ¥“çš„äº¤é€šæ–¹å¼æœ‰å“ªäº›ï¼Ÿ
# 2. å¤§é˜ªè³æ¥“çš„äº¤é€šæ–¹å¼æœ‰å“ªäº›ï¼Ÿ
# 3. äº¬éƒ½è³æ¥“æ™‚çš„æ“æ“ åº¦å¦‚ä½•ï¼Ÿ
# 4. å¤§é˜ªè³æ¥“æ™‚çš„æ“æ“ åº¦å¦‚ä½•ï¼Ÿ

result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    top_k=5,
    document_type="general"
)
```

**å„ªå‹¢ï¼š** å¾ä¸åŒè§’åº¦æª¢ç´¢ï¼Œæä¾›æ›´å…¨é¢çš„è³‡è¨Šã€‚

### å ´æ™¯ 4: å­¸è¡“ç ”ç©¶æŸ¥è©¢

**å•é¡Œç‰¹å¾µï¼š** éœ€è¦å¾å¤šå€‹è§’åº¦ç†è§£ä¸€å€‹ç ”ç©¶ä¸»é¡Œ

**ç¤ºä¾‹ï¼š**
```python
question = "How do neural networks learn, optimize, and generalize?"

# é æœŸç”Ÿæˆçš„å­å•é¡Œï¼š
# 1. How do neural networks learn?
# 2. How are neural networks optimized?
# 3. How do neural networks generalize?

result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    top_k=5,
    document_type="paper",
    metadata_filter={"arxiv_id": "1706.03762"}  # å¯é¸ï¼šé™åˆ¶ç¯„åœ
)
```

### å ´æ™¯ 5: åƒ…æª¢ç´¢å ´æ™¯

**é©ç”¨æƒ…æ³ï¼š** åªéœ€è¦æª¢ç´¢çµæœï¼Œä¸éœ€è¦ç”Ÿæˆç­”æ¡ˆ

**ç¤ºä¾‹ï¼š**
```python
# æ‰¹é‡æª¢ç´¢å¤šå€‹å•é¡Œ
questions = [
    "transformer architecture",
    "attention mechanism",
    "optimization techniques"
]

all_results = []
for q in questions:
    result = subquery_rag.query(
        question=q,
        top_k=5,
        return_sub_queries=True
    )
    all_results.append(result)
    
    print(f"å•é¡Œ: {q}")
    print(f"å­å•é¡Œ: {result['sub_queries']}")
    print(f"æ‰¾åˆ°æ–‡æª”: {result['total_docs_found']}")
    print()
```

---

## âš¡ æ€§èƒ½å„ªåŒ–

### 1. ä¸¦è¡Œè™•ç†å„ªåŒ–

**å»ºè­°ï¼š** å°æ–¼å¤šå€‹å­å•é¡Œï¼Œå§‹çµ‚å•Ÿç”¨ä¸¦è¡Œè™•ç†ã€‚

```python
# âœ… æ¨è–¦ï¼šä¸¦è¡Œè™•ç†
subquery_rag = SubQueryDecompositionRAG(
    ..., enable_parallel=True
)

# âŒ ä¸æ¨è–¦ï¼šä¸²è¡Œè™•ç†ï¼ˆé™¤éèª¿è©¦ï¼‰
subquery_rag = SubQueryDecompositionRAG(
    ..., enable_parallel=False
)
```

**æ€§èƒ½æå‡ï¼š**
- 3 å€‹å­å•é¡Œï¼šç´„ 3 å€é€Ÿåº¦æå‡
- 5 å€‹å­å•é¡Œï¼šç´„ 5 å€é€Ÿåº¦æå‡

### 2. å­å•é¡Œæ•¸é‡å„ªåŒ–

**åŸå‰‡ï¼š** æ ¹æ“šå•é¡Œè¤‡é›œåº¦å‹•æ…‹èª¿æ•´ã€‚

```python
def get_optimal_subquery_count(question: str) -> int:
    """æ ¹æ“šå•é¡Œè¤‡é›œåº¦è¿”å›æœ€å„ªå­å•é¡Œæ•¸é‡"""
    # ç°¡å–®å•Ÿç™¼å¼ï¼šåŸºæ–¼å•é¡Œé•·åº¦å’Œé—œéµè©æ•¸é‡
    length = len(question.split())
    if length < 10:
        return 2
    elif length < 20:
        return 3
    else:
        return 4

question = "æ¯”è¼ƒæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°ã€å„ªç¼ºé»å’Œæ‡‰ç”¨å ´æ™¯"
optimal_count = get_optimal_subquery_count(question)

subquery_rag = SubQueryDecompositionRAG(
    ..., max_sub_queries=optimal_count
)
```

### 3. æª¢ç´¢åƒæ•¸å„ªåŒ–

**æ ¹æ“šæ–‡æª”åº«å¤§å°èª¿æ•´ï¼š**

```python
# å°æ–‡æª”åº«ï¼ˆ<1000 chunksï¼‰
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=3
)

# ä¸­æ–‡æª”åº«ï¼ˆ1000-10000 chunksï¼‰
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=5
)

# å¤§æ–‡æª”åº«ï¼ˆ>10000 chunksï¼‰
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=10
)
```

### 4. LLM æ¨¡å‹é¸æ“‡

**æ€§èƒ½ vs è³ªé‡æ¬Šè¡¡ï¼š**

```python
# å¿«é€ŸéŸ¿æ‡‰ï¼ˆé©åˆç°¡å–®å•é¡Œï¼‰
llm = OllamaLLM(model_name="llama3.2:1b", timeout=60)

# å¹³è¡¡ï¼ˆæ¨è–¦ï¼‰
llm = OllamaLLM(model_name="llama3.2:3b", timeout=180)

# é«˜è³ªé‡ï¼ˆé©åˆè¤‡é›œå•é¡Œï¼‰
llm = OllamaLLM(model_name="deepseek-r1:7b", timeout=300)
```

### 5. ç·©å­˜ç­–ç•¥

**å°æ–¼é‡è¤‡æŸ¥è©¢ï¼Œå¯ä»¥å¯¦ç¾ç·©å­˜ï¼š**

```python
from functools import lru_cache

class CachedSubQueryRAG(SubQueryDecompositionRAG):
    @lru_cache(maxsize=100)
    def _generate_sub_queries_cached(self, question: str) -> tuple:
        """ç·©å­˜çš„å­å•é¡Œç”Ÿæˆ"""
        sub_queries = self._generate_sub_queries(question)
        return tuple(sub_queries)  # tuple æ‰èƒ½è¢« lru_cache ç·©å­˜
```

---

## ğŸ’¡ æœ€ä½³å¯¦è¸

### 1. å•é¡Œè¤‡é›œåº¦è©•ä¼°

**åœ¨æ±ºå®šæ˜¯å¦ä½¿ç”¨ Sub-query Decomposition ä¹‹å‰ï¼Œè©•ä¼°å•é¡Œè¤‡é›œåº¦ï¼š**

```python
def should_use_subquery(question: str) -> bool:
    """åˆ¤æ–·æ˜¯å¦æ‡‰è©²ä½¿ç”¨ Sub-query Decomposition"""
    # ç°¡å–®å•é¡Œï¼šç›´æ¥ä½¿ç”¨æ­£å¸¸ RAG
    simple_keywords = ["ä»€éº¼æ˜¯", "ä»€éº¼", "å®šç¾©", "what is", "define"]
    if any(kw in question.lower() for kw in simple_keywords):
        return False
    
    # è¤‡é›œå•é¡Œï¼šä½¿ç”¨ Sub-query Decomposition
    complex_keywords = ["æ¯”è¼ƒ", "å·®ç•°", "å„ªç¼ºé»", "æ¯”è¼ƒ", "compare", "difference"]
    if any(kw in question.lower() for kw in complex_keywords):
        return True
    
    # å¤šå€‹ä¸»é¡Œï¼šä½¿ç”¨ Sub-query Decomposition
    if question.count(",") >= 2 or question.count("å’Œ") >= 2:
        return True
    
    return False
```

### 2. åƒæ•¸èª¿å„ªæµç¨‹

**ç³»çµ±åŒ–èª¿å„ªï¼š**

1. **åˆå§‹è¨­ç½®ï¼š** ä½¿ç”¨é è¨­åƒæ•¸
2. **æ¸¬è©¦è©•ä¼°ï¼š** é‹è¡Œæ¸¬è©¦æŸ¥è©¢ï¼Œè©•ä¼°çµæœè³ªé‡
3. **èª¿æ•´åƒæ•¸ï¼š** æ ¹æ“šçµæœèª¿æ•´ `max_sub_queries` å’Œ `top_k_per_subquery`
4. **æ€§èƒ½æ¸¬è©¦ï¼š** æ¸¬é‡éŸ¿æ‡‰æ™‚é–“
5. **è¿­ä»£å„ªåŒ–ï¼š** é‡è¤‡æ­¥é©Ÿ 2-4

### 3. éŒ¯èª¤è™•ç†

**å®Œæ•´çš„éŒ¯èª¤è™•ç†ç¤ºä¾‹ï¼š**

```python
try:
    result = subquery_rag.generate_answer(
        question=question,
        formatter=formatter,
        top_k=5
    )
except ConnectionError as e:
    print(f"âŒ LLM é€£æ¥å¤±æ•—: {e}")
    print("è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œ: ollama serve")
except TimeoutError as e:
    print(f"âŒ è«‹æ±‚è¶…æ™‚: {e}")
    print("å»ºè­°ï¼šå¢åŠ  timeout æˆ–ä½¿ç”¨æ›´å°çš„æ¨¡å‹")
except Exception as e:
    print(f"âŒ æœªçŸ¥éŒ¯èª¤: {e}")
    import traceback
    traceback.print_exc()
```

### 4. æ—¥èªŒè¨˜éŒ„

**å•Ÿç”¨æ—¥èªŒä»¥è¿½è¹¤å•é¡Œï¼š**

```python
import logging

# é…ç½®æ—¥èªŒ
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# ä½¿ç”¨æ™‚æœƒè‡ªå‹•è¨˜éŒ„
result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    return_sub_queries=True  # è¨˜éŒ„å­å•é¡Œ
)
```

### 5. çµæœé©—è­‰

**é©—è­‰æª¢ç´¢çµæœè³ªé‡ï¼š**

```python
def validate_results(result: Dict) -> bool:
    """é©—è­‰æª¢ç´¢çµæœæ˜¯å¦åˆç†"""
    # æª¢æŸ¥æ˜¯å¦æœ‰çµæœ
    if not result.get('results'):
        print("âš ï¸  æœªæ‰¾åˆ°ä»»ä½•çµæœ")
        return False
    
    # æª¢æŸ¥å­å•é¡Œæ•¸é‡
    sub_queries = result.get('sub_queries', [])
    if len(sub_queries) < 2:
        print("âš ï¸  åªç”Ÿæˆäº†å°‘é‡å­å•é¡Œï¼Œå¯èƒ½ä¸é©åˆä½¿ç”¨ Sub-query Decomposition")
    
    # æª¢æŸ¥æ–‡æª”æ•¸é‡
    if result['total_docs_found'] < 3:
        print("âš ï¸  æ‰¾åˆ°çš„æ–‡æª”è¼ƒå°‘ï¼Œå¯èƒ½å½±éŸ¿ç­”æ¡ˆè³ªé‡")
    
    # æª¢æŸ¥åˆ†æ•¸
    scores = [doc.get('rerank_score', doc.get('hybrid_score', 0)) 
              for doc in result['results']]
    if max(scores) < 0.5:
        print("âš ï¸  æœ€é«˜åˆ†æ•¸è¼ƒä½ï¼Œæª¢ç´¢çµæœå¯èƒ½ä¸å¤ ç›¸é—œ")
    
    return True

result = subquery_rag.generate_answer(...)
if validate_results(result):
    print("âœ… çµæœé©—è­‰é€šé")
```

---

## ğŸ”„ èˆ‡æ­£å¸¸ RAG çš„å°æ¯”

### è©³ç´°å°æ¯”è¡¨

| ç‰¹æ€§ | æ­£å¸¸ RAG | Sub-query Decomposition RAG |
|------|---------|------------------------------|
| **é©ç”¨å ´æ™¯** | ç°¡å–®ã€å–®ä¸€å•é¡Œ | è¤‡é›œã€å¤šé¢å‘å•é¡Œ |
| **æŸ¥è©¢ç¤ºä¾‹** | "ä»€éº¼æ˜¯æ©Ÿå™¨å­¸ç¿’ï¼Ÿ" | "æ¯”è¼ƒæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°ã€å„ªç¼ºé»" |
| **æª¢ç´¢æ–¹å¼** | å–®ä¸€æŸ¥è©¢ | å¤šå€‹å­æŸ¥è©¢ |
| **æª¢ç´¢è¦†è“‹ç‡** | å¯èƒ½éºæ¼æŸäº›é¢å‘ | æ›´å…¨é¢çš„è¦†è“‹ |
| **éŸ¿æ‡‰æ™‚é–“** | è¼ƒå¿«ï¼ˆ~2-5ç§’ï¼‰ | ç¨æ…¢ï¼ˆ~5-15ç§’ï¼Œå–æ±ºæ–¼å­å•é¡Œæ•¸ï¼‰ |
| **è³‡æºæ¶ˆè€—** | è¼ƒä½ | è¼ƒé«˜ï¼ˆéœ€è¦é¡å¤– LLM èª¿ç”¨ï¼‰ |
| **æº–ç¢ºæ€§ï¼ˆç°¡å–®å•é¡Œï¼‰** | è¼ƒå¥½ | å¯èƒ½éåº¦è¤‡é›œåŒ– |
| **æº–ç¢ºæ€§ï¼ˆè¤‡é›œå•é¡Œï¼‰** | å¯èƒ½éºæ¼è³‡è¨Š | æ›´å¥½ |
| **å¯¦ç¾è¤‡é›œåº¦** | ç°¡å–® | ä¸­ç­‰ |
| **ç¶­è­·æˆæœ¬** | ä½ | ä¸­ç­‰ |

### æ€§èƒ½å°æ¯”ç¤ºä¾‹

**æ¸¬è©¦æŸ¥è©¢ï¼š** "transformer architecture, attention mechanism, and optimization techniques"

**æ­£å¸¸ RAGï¼š**
- æª¢ç´¢æ™‚é–“ï¼š2.3 ç§’
- æ‰¾åˆ°æ–‡æª”ï¼š5 å€‹
- ç¸½è€—æ™‚ï¼š8.5 ç§’

**Sub-query Decomposition RAGï¼š**
- å­å•é¡Œç”Ÿæˆï¼š1.2 ç§’
- æª¢ç´¢æ™‚é–“ï¼š3.1 ç§’ï¼ˆä¸¦è¡Œï¼‰
- æ‰¾åˆ°æ–‡æª”ï¼š12 å€‹ï¼ˆå»é‡å¾Œ 8 å€‹ï¼‰
- ç¸½è€—æ™‚ï¼š12.8 ç§’

**çµè«–ï¼š** Sub-query RAG æ‰¾åˆ°æ›´å¤šç›¸é—œæ–‡æª”ï¼Œä½†è€—æ™‚æ›´é•·ã€‚

### ä½•æ™‚ä½¿ç”¨å“ªç¨®æ–¹æ³•ï¼Ÿ

**ä½¿ç”¨æ­£å¸¸ RAG çš„æƒ…æ³ï¼š**
- âœ… ç°¡å–®çš„äº‹å¯¦æ€§æŸ¥è©¢
- âœ… å–®ä¸€æ¦‚å¿µçš„å•é¡Œ
- âœ… å°éŸ¿æ‡‰æ™‚é–“è¦æ±‚æ¥µé«˜
- âœ… è³‡æºå—é™çš„ç’°å¢ƒ

**ä½¿ç”¨ Sub-query Decomposition RAG çš„æƒ…æ³ï¼š**
- âœ… è¤‡é›œçš„æ¯”è¼ƒå•é¡Œ
- âœ… å¤šé¢å‘æŸ¥è©¢
- âœ… éœ€è¦å…¨é¢è¦†è“‹çš„å ´æ™¯
- âœ… ç­”æ¡ˆè³ªé‡å„ªå…ˆæ–¼éŸ¿æ‡‰æ™‚é–“

---

## ğŸ”§ æ•…éšœæ’é™¤

### å•é¡Œ 1: LLM é€£æ¥å¤±æ•—

**ç—‡ç‹€ï¼š**
```
ConnectionError: ç„¡æ³•é€£æ¥åˆ° Ollama æœå‹™
```

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. æª¢æŸ¥ Ollama æ˜¯å¦é‹è¡Œï¼š
```bash
ollama serve
```

2. æª¢æŸ¥ Ollama API æ˜¯å¦å¯è¨ªå•ï¼š
```bash
curl http://localhost:11434/api/tags
```

3. æª¢æŸ¥æ¨¡å‹æ˜¯å¦å·²ä¸‹è¼‰ï¼š
```bash
ollama list
```

### å•é¡Œ 2: å­å•é¡Œç”Ÿæˆå¤±æ•—

**ç—‡ç‹€ï¼š** è¿”å›çš„ `sub_queries` ç‚ºç©ºæˆ–åªæœ‰åŸå§‹å•é¡Œ

**å¯èƒ½åŸå› ï¼š**
- LLM æ¨¡å‹å¤ªå°æˆ–è³ªé‡ä¸ä½³
- å•é¡Œæ ¼å¼ä¸æ­£ç¢º
- LLM è¶…æ™‚

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. ä½¿ç”¨æ›´å¥½çš„æ¨¡å‹ï¼š
```python
llm = OllamaLLM(model_name="llama3.2:3b")  # è€Œä¸æ˜¯ 1b
```

2. å¢åŠ è¶…æ™‚æ™‚é–“ï¼š
```python
llm = OllamaLLM(model_name="llama3.2:3b", timeout=300)
```

3. æª¢æŸ¥å•é¡Œæ ¼å¼ï¼š
```python
# ç¢ºä¿å•é¡Œä¸æ˜¯ç©ºçš„
assert len(question.strip()) > 0
```

### å•é¡Œ 3: æª¢ç´¢çµæœç‚ºç©º

**ç—‡ç‹€ï¼š** `total_docs_found` ç‚º 0

**å¯èƒ½åŸå› ï¼š**
- æ–‡æª”åº«ä¸­æ²’æœ‰ç›¸é—œå…§å®¹
- `metadata_filter` éæ–¼åš´æ ¼
- æª¢ç´¢åƒæ•¸è¨­ç½®ä¸ç•¶

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. æª¢æŸ¥æ–‡æª”åº«ï¼š
```python
print(f"æ–‡æª”åº«å¤§å°: {len(documents)} chunks")
```

2. æ”¾å¯¬ `metadata_filter`ï¼š
```python
# ç§»é™¤éæ¿¾æ¢ä»¶æ¸¬è©¦
result = subquery_rag.query(question, top_k=5)  # ä¸ä½¿ç”¨ metadata_filter
```

3. å¢åŠ  `top_k_per_subquery`ï¼š
```python
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=10  # å¢åŠ æª¢ç´¢æ•¸é‡
)
```

### å•é¡Œ 4: æ€§èƒ½å•é¡Œ

**ç—‡ç‹€ï¼š** éŸ¿æ‡‰æ™‚é–“éé•·

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. å•Ÿç”¨ä¸¦è¡Œè™•ç†ï¼š
```python
subquery_rag = SubQueryDecompositionRAG(
    ..., enable_parallel=True
)
```

2. æ¸›å°‘å­å•é¡Œæ•¸é‡ï¼š
```python
subquery_rag = SubQueryDecompositionRAG(
    ..., max_sub_queries=2  # æ¸›å°‘åˆ° 2 å€‹
)
```

3. æ¸›å°‘æ¯å€‹å­æŸ¥è©¢çš„ top_kï¼š
```python
subquery_rag = SubQueryDecompositionRAG(
    ..., top_k_per_subquery=3  # æ¸›å°‘æª¢ç´¢æ•¸é‡
)
```

4. ä½¿ç”¨æ›´å¿«çš„ LLM æ¨¡å‹ï¼š
```python
llm = OllamaLLM(model_name="llama3.2:1b")  # æ›´å¿«çš„æ¨¡å‹
```

### å•é¡Œ 5: ç­”æ¡ˆè³ªé‡ä¸ä½³

**ç—‡ç‹€ï¼š** ç”Ÿæˆçš„ç­”æ¡ˆä¸æº–ç¢ºæˆ–ä¸å®Œæ•´

**è§£æ±ºæ–¹æ¡ˆï¼š**
1. å¢åŠ ç”¨æ–¼ç”Ÿæˆç­”æ¡ˆçš„æ–‡æª”æ•¸é‡ï¼š
```python
result = subquery_rag.generate_answer(
    ..., top_k=10  # å¢åŠ æ–‡æª”æ•¸é‡
)
```

2. ä½¿ç”¨æ›´å¥½çš„ LLM æ¨¡å‹ç”Ÿæˆç­”æ¡ˆï¼š
```python
# å¯ä»¥ç‚ºç”Ÿæˆç­”æ¡ˆä½¿ç”¨ä¸åŒçš„ LLM
answer_llm = OllamaLLM(model_name="deepseek-r1:7b")
# æ³¨æ„ï¼šé€™éœ€è¦ä¿®æ”¹ generate_answer æ–¹æ³•
```

3. èª¿æ•´ prompt æ ¼å¼ï¼š
```python
formatter = PromptFormatter(
    format_style="detailed",  # ä½¿ç”¨è©³ç´°æ ¼å¼
    include_metadata=True
)
```

---

## â“ å¸¸è¦‹å•é¡Œ

### Q1: Sub-query Decomposition æ˜¯å¦ç¸½æ˜¯æ¯”æ­£å¸¸ RAG å¥½ï¼Ÿ

**A:** ä¸æ˜¯ã€‚å°æ–¼ç°¡å–®å•é¡Œï¼Œæ­£å¸¸ RAG å¯èƒ½æ›´å¿«ã€æ›´æº–ç¢ºã€‚Sub-query Decomposition ä¸»è¦å„ªå‹¢åœ¨æ–¼è™•ç†è¤‡é›œã€å¤šé¢å‘çš„å•é¡Œã€‚

### Q2: å­å•é¡Œæ•¸é‡æ‡‰è©²è¨­ç½®ç‚ºå¤šå°‘ï¼Ÿ

**A:** ä¸€èˆ¬å»ºè­° 2-5 å€‹ã€‚å¤ªå°‘å¯èƒ½ç„¡æ³•å……åˆ†æ‹†è§£å•é¡Œï¼Œå¤ªå¤šæœƒå¢åŠ æª¢ç´¢æ™‚é–“ã€‚å¯ä»¥æ ¹æ“šå•é¡Œè¤‡é›œåº¦å‹•æ…‹èª¿æ•´ã€‚

### Q3: ä¸¦è¡Œè™•ç†æ˜¯å¦ç¸½æ˜¯æ›´å¿«ï¼Ÿ

**A:** æ˜¯çš„ï¼Œå°æ–¼å¤šå€‹å­å•é¡Œï¼Œä¸¦è¡Œè™•ç†é€šå¸¸èƒ½é¡¯è‘—æå‡æ€§èƒ½ã€‚ä½†å°æ–¼å–®å€‹å­å•é¡Œï¼Œä¸¦è¡Œè™•ç†æ²’æœ‰æ„ç¾©ã€‚

### Q4: å¦‚ä½•åˆ¤æ–·å•é¡Œæ˜¯å¦é©åˆä½¿ç”¨ Sub-query Decompositionï¼Ÿ

**A:** å¦‚æœå•é¡ŒåŒ…å«ä»¥ä¸‹ç‰¹å¾µï¼Œé©åˆä½¿ç”¨ï¼š
- å¤šå€‹å¯¦é«”çš„æ¯”è¼ƒ
- å¤šå€‹é¢å‘çš„æŸ¥è©¢
- å¤šå€‹é—œéµè©æˆ–æ¦‚å¿µ
- éœ€è¦å…¨é¢è¦†è“‹çš„å ´æ™¯

### Q5: å»é‡æ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ

**A:** ç³»çµ±å„ªå…ˆä½¿ç”¨ metadata ä¸­çš„å”¯ä¸€æ¨™è­˜ï¼ˆå¦‚ `arxiv_id + chunk_index`ï¼‰ï¼Œå¦‚æœæ²’æœ‰ï¼Œå‰‡ä½¿ç”¨å…§å®¹çš„ MD5 hashã€‚å¦‚æœåŒä¸€æ–‡æª”åœ¨å¤šå€‹å­å•é¡Œçš„çµæœä¸­å‡ºç¾ï¼Œä¿ç•™åˆ†æ•¸æ›´é«˜çš„ç‰ˆæœ¬ã€‚

### Q6: å¯ä»¥è‡ªå®šç¾©å­å•é¡Œç”Ÿæˆçš„ prompt å—ï¼Ÿ

**A:** ç›®å‰ä¸æ”¯æŒç›´æ¥è‡ªå®šç¾©ï¼Œä½†å¯ä»¥é€šéä¿®æ”¹ `SubQueryDecompositionRAG` é¡çš„ `_generate_sub_queries` æ–¹æ³•ä¾†å¯¦ç¾ã€‚

### Q7: æ”¯æŒå“ªäº›èªè¨€ï¼Ÿ

**A:** ç›®å‰æ”¯æŒä¸­æ–‡å’Œè‹±æ–‡ã€‚ç³»çµ±æœƒè‡ªå‹•æª¢æ¸¬å•é¡Œèªè¨€ä¸¦ä½¿ç”¨ç›¸æ‡‰çš„ promptã€‚

### Q8: å¦‚ä½•è™•ç†è¶…æ™‚å•é¡Œï¼Ÿ

**A:** å¯ä»¥å¢åŠ  LLM çš„ timeout åƒæ•¸ï¼š
```python
llm = OllamaLLM(model_name="llama3.2:3b", timeout=300)  # 5 åˆ†é˜
```

---

## ğŸ§ª æ¸¬è©¦èˆ‡é©—è­‰

### é‹è¡ŒåŸºæœ¬æ¸¬è©¦

```bash
# åŸºæœ¬åŠŸèƒ½æ¸¬è©¦
python test_subquery_rag.py
```

### é‹è¡Œå°æ¯”æ¸¬è©¦

```bash
# å°æ¯” Sub-query RAG å’Œæ­£å¸¸ RAG
python test_subquery_rag.py --compare
```

### æ¸¬è©¦è¼¸å‡ºè§£è®€

**åŸºæœ¬æ¸¬è©¦è¼¸å‡ºï¼š**
- å­å•é¡Œåˆ—è¡¨
- æª¢ç´¢åˆ°çš„æ–‡æª”
- ç”Ÿæˆçš„ç­”æ¡ˆ
- æ€§èƒ½çµ±è¨ˆ

**å°æ¯”æ¸¬è©¦è¼¸å‡ºï¼š**
- å…©ç¨®æ–¹æ³•çš„æ€§èƒ½å°æ¯”
- æª¢ç´¢çµæœå°æ¯”
- æ–‡æª”é‡ç–Šåˆ†æ
- è‡ªå‹•è§€å¯Ÿå’Œå»ºè­°

### è‡ªå®šç¾©æ¸¬è©¦

```python
# æ¸¬è©¦ç‰¹å®šå•é¡Œ
question = "ä½ çš„æ¸¬è©¦å•é¡Œ"
result = subquery_rag.generate_answer(
    question=question,
    formatter=formatter,
    return_sub_queries=True
)

# é©—è­‰çµæœ
assert result['total_docs_found'] > 0, "æ‡‰è©²æ‰¾åˆ°è‡³å°‘ä¸€å€‹æ–‡æª”"
assert len(result.get('sub_queries', [])) > 0, "æ‡‰è©²ç”Ÿæˆè‡³å°‘ä¸€å€‹å­å•é¡Œ"
assert len(result['answer']) > 0, "æ‡‰è©²ç”Ÿæˆç­”æ¡ˆ"
```

---

## ğŸ“š åƒè€ƒè³‡æ–™

### ç›¸é—œæ–‡æª”

- [LangChain Sub-query Decomposition](https://python.langchain.com/docs/use_cases/question_answering/how_to/decompose/)
- [RAG æœ€ä½³å¯¦è¸](https://www.pinecone.io/learn/retrieval-augmented-generation/)
- [æœ¬é …ç›® README](../README.md)

### ç›¸é—œæŠ€è¡“

- **RAG (Retrieval-Augmented Generation)**: æª¢ç´¢å¢å¼·ç”Ÿæˆ
- **Hybrid Search**: æ··åˆæœå°‹ï¼ˆBM25 + å‘é‡æª¢ç´¢ï¼‰
- **Reranking**: é‡æ’åºæŠ€è¡“
- **Query Decomposition**: æŸ¥è©¢æ‹†è§£æŠ€è¡“

---

## ğŸ“ æ›´æ–°æ—¥èªŒ

### v1.0.0 (ç•¶å‰ç‰ˆæœ¬)

- åˆå§‹å¯¦ç¾ Sub-query Decomposition RAG
- æ”¯æŒä¸¦è¡Œ/ä¸²è¡Œæª¢ç´¢
- æ”¯æŒè‡ªå‹•å»é‡
- æ”¯æŒä¸­è‹±æ–‡å•é¡Œ

---

## ğŸ¤ è²¢ç»

å¦‚æœ‰å•é¡Œæˆ–å»ºè­°ï¼Œè«‹æäº¤ Issue æˆ– Pull Requestã€‚

---

**æœ€å¾Œæ›´æ–°ï¼š** 2024å¹´
