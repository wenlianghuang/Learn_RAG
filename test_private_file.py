"""
æ¸¬è©¦ç§æœ‰æª”æ¡ˆçš„ RAG æ•ˆæœ

é€™å€‹è…³æœ¬æ¼”ç¤ºå¦‚ä½•ï¼š
1. è¼‰å…¥ç§æœ‰æª”æ¡ˆï¼ˆPDF, DOCX, TXTï¼‰
2. å»ºç«‹ RAG ç³»çµ±
3. å°æ¯”æ¸¬è©¦ï¼šæœ‰ RAG vs ç„¡ RAG çš„æ•ˆæœ
"""
import os
import sys
from pathlib import Path
from src import (
    DocumentProcessor,
    BM25Retriever,
    VectorRetriever,
    HybridSearch,
    Reranker,
    RAGPipeline,
    PromptFormatter,
    OllamaLLM
)
from main import test_rag_vs_no_rag


def main():
    print("=" * 60)
    print("ç§æœ‰æª”æ¡ˆ RAG æ¸¬è©¦")
    print("=" * 60)
    
    # ========== æ­¥é©Ÿ 1: æº–å‚™ç§æœ‰æª”æ¡ˆ ==========
    print("\n[æ­¥é©Ÿ 1] æº–å‚™ç§æœ‰æª”æ¡ˆ")
    print("-" * 60)
    
    # æç¤ºç”¨æˆ¶è¼¸å…¥æª”æ¡ˆè·¯å¾‘
    if len(sys.argv) > 1:
        file_path = sys.argv[1]
    else:
        # é è¨­ç¤ºä¾‹ï¼šå¯ä»¥ä¿®æ”¹ç‚ºä½ çš„æª”æ¡ˆè·¯å¾‘
        file_path = input("\nè«‹è¼¸å…¥æª”æ¡ˆè·¯å¾‘ï¼ˆPDF, DOCX, æˆ– TXTï¼‰: ").strip()
        
        if not file_path:
            print("\nâš ï¸  æœªæä¾›æª”æ¡ˆè·¯å¾‘")
            print("\nä½¿ç”¨æ–¹æ³•ï¼š")
            print("  python test_private_file.py <æª”æ¡ˆè·¯å¾‘>")
            print("\næˆ–ç›´æ¥é‹è¡Œï¼Œç„¶å¾Œè¼¸å…¥æª”æ¡ˆè·¯å¾‘")
            print("\nç¯„ä¾‹ï¼š")
            print("  python test_private_file.py ./documents/my_document.pdf")
            return
    
    file_path = Path(file_path)
    
    if not file_path.exists():
        print(f"\nâŒ æª”æ¡ˆä¸å­˜åœ¨: {file_path}")
        print("\nè«‹ç¢ºèªï¼š")
        print("  1. æª”æ¡ˆè·¯å¾‘æ˜¯å¦æ­£ç¢º")
        print("  2. æª”æ¡ˆæ˜¯å¦å­˜åœ¨")
        return
    
    print(f"âœ“ æ‰¾åˆ°æª”æ¡ˆ: {file_path}")
    print(f"  æª”æ¡ˆé¡å‹: {file_path.suffix}")
    print(f"  æª”æ¡ˆå¤§å°: {file_path.stat().st_size / 1024:.2f} KB")
    
    # ========== æ­¥é©Ÿ 2: è™•ç†æª”æ¡ˆ ==========
    print("\n[æ­¥é©Ÿ 2] è™•ç†æª”æ¡ˆä¸¦åˆ†å‰²æˆ chunks")
    print("-" * 60)
    
    try:
        processor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)
        documents = processor.process_file(str(file_path))
        print(f"âœ“ è™•ç†å®Œæˆï¼Œå‰µå»ºäº† {len(documents)} å€‹ chunks")
        
        if documents:
            print(f"\nç¯„ä¾‹ chunkï¼ˆç¬¬ä¸€å€‹ï¼‰ï¼š")
            print(f"  æ¨™é¡Œ: {documents[0]['metadata']['title']}")
            print(f"  å…§å®¹é è¦½: {documents[0]['content'][:150]}...")
    except Exception as e:
        print(f"\nâŒ è™•ç†æª”æ¡ˆå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ========== æ­¥é©Ÿ 3: åˆå§‹åŒ–æª¢ç´¢ç³»çµ± ==========
    print("\n[æ­¥é©Ÿ 3] åˆå§‹åŒ–æª¢ç´¢ç³»çµ±")
    print("-" * 60)
    
    try:
        print("  - åˆå§‹åŒ– BM25 æª¢ç´¢å™¨...")
        bm25_retriever = BM25Retriever(documents)
        
        print("  - åˆå§‹åŒ–å‘é‡æª¢ç´¢å™¨...")
        # ä½¿ç”¨ä¸åŒçš„è³‡æ–™åº«ç›®éŒ„é¿å…èˆ‡ä¸»ç¨‹åºè¡çª
        vector_retriever = VectorRetriever(
            documents,
            embedding_model="sentence-transformers/all-MiniLM-L6-v2",
            persist_directory="./chroma_db_private"
        )
        
        print("  - åˆå§‹åŒ–æ··åˆæœå°‹...")
        hybrid_search = HybridSearch(
            sparse_retriever=bm25_retriever,
            dense_retriever=vector_retriever,
            fusion_method="rrf",
            rrf_k=60
        )
        
        print("âœ“ æª¢ç´¢ç³»çµ±åˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"\nâŒ æª¢ç´¢ç³»çµ±åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ========== æ­¥é©Ÿ 4: åˆå§‹åŒ–é‡æ’åºå’Œ RAG ç®¡ç·š ==========
    print("\n[æ­¥é©Ÿ 4] åˆå§‹åŒ–é‡æ’åºå’Œ RAG ç®¡ç·š")
    print("-" * 60)
    
    try:
        print("  - åˆå§‹åŒ–é‡æ’åºå™¨...")
        reranker = Reranker(
            model_name="BAAI/bge-reranker-base",
            batch_size=16
        )
        
        print("  - åˆå§‹åŒ– RAG ç®¡ç·š...")
        rag_pipeline = RAGPipeline(
            hybrid_search=hybrid_search,
            reranker=reranker,
            recall_k=20,
            adaptive_recall=True
        )
        
        print("âœ“ RAG ç®¡ç·šåˆå§‹åŒ–å®Œæˆ")
    except Exception as e:
        print(f"\nâŒ RAG ç®¡ç·šåˆå§‹åŒ–å¤±æ•—: {e}")
        print("   é€™å¯èƒ½æ˜¯å› ç‚ºé‡æ’åºæ¨¡å‹ä¸‹è¼‰å¤±æ•—")
        print("   ä½ å¯ä»¥ç¹¼çºŒä½¿ç”¨æ··åˆæœå°‹ï¼ˆä¸é€²è¡Œé‡æ’åºï¼‰")
        return
    
    # ========== æ­¥é©Ÿ 5: åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨ ==========
    print("\n[æ­¥é©Ÿ 5] åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨")
    print("-" * 60)
    
    try:
        print("  - åˆå§‹åŒ– Prompt æ ¼å¼åŒ–å™¨...")
        formatter = PromptFormatter(format_style="detailed")
        
        print("  - åˆå§‹åŒ– Ollama LLM...")
        # é¡¯ç¤ºæ¨è–¦çš„æ¨¡å‹
        OllamaLLM.print_recommended_models()
        
        llm = OllamaLLM(
            model_name="llama3.2:3b",  # é©åˆ 16GB å…§å­˜
            timeout=180
        )
        
        print("âœ“ LLM å’Œæ ¼å¼åŒ–å™¨åˆå§‹åŒ–å®Œæˆ")
    except ConnectionError as e:
        print(f"\nâŒ Ollama é€£æ¥å¤±æ•—: {e}")
        print("\nè«‹æŒ‰ç…§ä»¥ä¸‹æ­¥é©Ÿè¨­ç½® Ollamaï¼š")
        print("  1. å®‰è£ Ollama: https://ollama.ai/download")
        print("  2. å•Ÿå‹• Ollama æœå‹™ï¼ˆé€šå¸¸æœƒè‡ªå‹•å•Ÿå‹•ï¼‰")
        print("  3. ä¸‹è¼‰æ¨¡å‹: ollama pull llama3.2:3b")
        print("  4. é‡æ–°é‹è¡Œæ­¤ç¨‹åº")
        return
    except Exception as e:
        print(f"\nâŒ åˆå§‹åŒ–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return
    
    # ========== æ­¥é©Ÿ 6: æ¸¬è©¦å•é¡Œ ==========
    print("\n[æ­¥é©Ÿ 6] æº–å‚™æ¸¬è©¦å•é¡Œ")
    print("-" * 60)
    
    # æç¤ºç”¨æˆ¶è¼¸å…¥å•é¡Œ
    if len(sys.argv) > 2:
        test_query = " ".join(sys.argv[2:])
    else:
        print("\nè«‹è¼¸å…¥ä¸€å€‹æ¸¬è©¦å•é¡Œï¼ˆæ‡‰è©²æ¶‰åŠä½ çš„ç§æœ‰æ–‡æª”å…§å®¹ï¼‰ï¼š")
        print("ç¯„ä¾‹ï¼š")
        print("  - 'é€™ä»½æ–‡æª”çš„ä¸»è¦å…§å®¹æ˜¯ä»€éº¼ï¼Ÿ'")
        print("  - 'æ–‡æª”ä¸­æåˆ°äº†å“ªäº›é—œéµæ¦‚å¿µï¼Ÿ'")
        print("  - 'æ–‡æª”çš„çµè«–æ˜¯ä»€éº¼ï¼Ÿ'")
        test_query = input("\nä½ çš„å•é¡Œ: ").strip()
    
    if not test_query:
        print("\nâš ï¸  æœªæä¾›æ¸¬è©¦å•é¡Œ")
        print("ä½¿ç”¨é è¨­å•é¡Œ...")
        test_query = "é€™ä»½æ–‡æª”çš„ä¸»è¦å…§å®¹æ˜¯ä»€éº¼ï¼Ÿ"
    
    print(f"\nâœ“ æ¸¬è©¦å•é¡Œ: '{test_query}'")
    
    # ========== æ­¥é©Ÿ 7: åŸ·è¡Œå°æ¯”æ¸¬è©¦ ==========
    print("\n" + "=" * 60)
    print("é–‹å§‹åŸ·è¡Œå°æ¯”æ¸¬è©¦")
    print("=" * 60)
    
    test_rag_vs_no_rag(
        llm=llm,
        rag_pipeline=rag_pipeline,
        formatter=formatter,
        query=test_query,
        test_file_path=str(file_path)
    )
    
    print("\n" + "=" * 60)
    print("æ¸¬è©¦å®Œæˆï¼")
    print("=" * 60)
    print("\nğŸ’¡ æç¤ºï¼š")
    print("  - å¦‚æœç„¡ RAG çš„å›ç­”ä¸æº–ç¢ºæˆ–ç„¡æ³•å›ç­”ï¼Œä½†æœ‰ RAG çš„å›ç­”æ­£ç¢ºï¼Œ")
    print("    é€™è­‰æ˜äº† RAG ç³»çµ±çš„æœ‰æ•ˆæ€§ï¼")
    print("  - ä½ å¯ä»¥å˜—è©¦ä¸åŒçš„å•é¡Œä¾†æ¸¬è©¦ç³»çµ±çš„å„ç¨®æƒ…æ³")


if __name__ == "__main__":
    main()

