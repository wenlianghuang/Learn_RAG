"""
HyDE RAG æ¸¬è©¦è…³æœ¬ï¼šæ¸¬è©¦ HyDE ä¸¦èˆ‡å‚³çµ± RAG é€²è¡Œå°æ¯”
"""
import os
import sys
import time
from src import (
    DocumentProcessor,
    BM25Retriever,
    VectorRetriever,
    HybridSearch,
    Reranker,
    RAGPipeline,
    PromptFormatter,
    OllamaLLM,
    HyDERAG,
    SubQueryDecompositionRAG,
    HybridSubqueryHyDERAG
)


def test_hyde_vs_normal_rag():
    """å°æ¯”æ¸¬è©¦ï¼šHyDE RAG vs æ­£å¸¸ RAG"""
    print("=" * 60)
    print("HyDE RAG vs æ­£å¸¸ RAG å°æ¯”æ¸¬è©¦")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–ç³»çµ±
    print("\n[åˆå§‹åŒ–ç³»çµ±]")
    processor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)
    
    print("å¾ arXiv ç²å–è«–æ–‡...")
    papers = processor.fetch_papers(
        query="cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
        max_results=20
    )
    print(f"âœ… ç²å–äº† {len(papers)} ç¯‡è«–æ–‡")
    
    documents = processor.process_documents(papers)
    print(f"âœ… ç¸½å…±å‰µå»ºäº† {len(documents)} å€‹æ–‡æª” chunks")
    
    # åˆå§‹åŒ–æª¢ç´¢å™¨
    print("åˆå§‹åŒ–æª¢ç´¢å™¨...")
    bm25_retriever = BM25Retriever(documents)
    vector_retriever = VectorRetriever(
        documents,
        embedding_model="sentence-transformers/all-MiniLM-L6-v2",
        persist_directory="./chroma_db_hyde"
    )
    hybrid_search = HybridSearch(
        sparse_retriever=bm25_retriever,
        dense_retriever=vector_retriever,
        fusion_method="rrf",
        rrf_k=60
    )
    
    reranker = Reranker(
        model_name="BAAI/bge-reranker-base",
        device=None,
        batch_size=16
    )
    rag_pipeline = RAGPipeline(
        hybrid_search=hybrid_search,
        reranker=reranker,
        recall_k=25,
        adaptive_recall=True
    )
    
    # åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨
    print("åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨...")
    try:
        llm = OllamaLLM(model_name="llama3.2:3b", timeout=180)
        print(f"âœ… LLM åˆå§‹åŒ–å®Œæˆ: {llm.model_name}")
    except Exception as e:
        print(f"âš ï¸  LLM åˆå§‹åŒ–å¤±æ•—: {e}")
        print("è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œä¸¦å·²ä¸‹è¼‰æ¨¡å‹")
        return
    
    formatter = PromptFormatter(
        include_metadata=True,
        format_style="detailed"
    )
    
    # åˆå§‹åŒ– HyDE RAG
    print("åˆå§‹åŒ– HyDE RAG...")
    hyde_rag = HyDERAG(
        rag_pipeline=rag_pipeline,
        vector_retriever=vector_retriever,
        llm=llm,
        hypothetical_length=200,
        temperature=0.7
    )
    print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
    
    # 2. æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "ä»€éº¼æ˜¯å€å¡Šéˆçš„å…±è­˜æ©Ÿåˆ¶ï¼Ÿ",
        "transformer architecture and attention mechanism",
        "How do neural networks learn and optimize?",
        "æ·±åº¦å­¸ç¿’ä¸­çš„åå‘å‚³æ’­ç®—æ³•åŸç†",
    ]
    
    print("\n" + "=" * 60)
    print("é–‹å§‹å°æ¯”æ¸¬è©¦")
    print("=" * 60)
    
    for query in test_queries:
        print("\n" + "=" * 60)
        print(f"æ¸¬è©¦æŸ¥è©¢: '{query}'")
        print("=" * 60)
        
        # === æ–¹æ³• 1: æ­£å¸¸ RAGï¼ˆä½¿ç”¨åŸå§‹å•é¡Œæª¢ç´¢ï¼‰===
        print("\n[æ–¹æ³• 1] æ­£å¸¸ RAGï¼ˆåŸå§‹å•é¡Œæª¢ç´¢ï¼‰")
        print("-" * 60)
        
        normal_start = time.time()
        try:
            # æ­£å¸¸ RAGï¼šç›´æ¥ä½¿ç”¨åŸå§‹å•é¡Œæª¢ç´¢
            normal_results = vector_retriever.retrieve(
                query=query,  # ä½¿ç”¨åŸå§‹å•é¡Œ
                top_k=5
            )
            
            # æ ¼å¼åŒ–ä¸¦ç”Ÿæˆç­”æ¡ˆ
            normal_context = formatter.format_context(
                normal_results,
                document_type="paper"
            )
            normal_prompt = formatter.create_prompt(
                query,
                normal_context,
                document_type="paper"
            )
            
            normal_answer_start = time.time()
            normal_answer = llm.generate(
                prompt=normal_prompt,
                temperature=0.7,
                max_tokens=2048
            )
            normal_answer_time = time.time() - normal_answer_start
            normal_total_time = time.time() - normal_start
            
            print(f"âœ… æ­£å¸¸ RAG å®Œæˆ")
            print(f"   æª¢ç´¢è€—æ™‚: {normal_total_time - normal_answer_time:.2f}s")
            print(f"   ç”Ÿæˆè€—æ™‚: {normal_answer_time:.2f}s")
            print(f"   ç¸½è€—æ™‚: {normal_total_time:.2f}s")
            print(f"   æ‰¾åˆ°æ–‡æª”æ•¸: {len(normal_results)}")
            
            # é¡¯ç¤ºæª¢ç´¢çµæœ
            print(f"\n   æª¢ç´¢åˆ°çš„æ–‡æª” (å‰ 3 å€‹):")
            for i, doc in enumerate(normal_results[:3], 1):
                score = doc.get('score', 0)
                title = doc['metadata'].get('title', 'N/A')
                if len(title) > 50:
                    title = title[:47] + "..."
                print(f"   {i}. {title} (åˆ†æ•¸: {score:.4f})")
            
        except Exception as e:
            print(f"âŒ æ­£å¸¸ RAG å‡ºéŒ¯: {e}")
            normal_answer = None
            normal_total_time = 0
            normal_results = []
            import traceback
            traceback.print_exc()
        
        # === æ–¹æ³• 2: HyDE RAGï¼ˆä½¿ç”¨å‡è¨­æ€§æ–‡æª”æª¢ç´¢ï¼‰===
        print("\n[æ–¹æ³• 2] HyDE RAGï¼ˆå‡è¨­æ€§æ–‡æª”æª¢ç´¢ï¼‰")
        print("-" * 60)
        
        try:
            hyde_result = hyde_rag.generate_answer(
                question=query,
                formatter=formatter,
                top_k=5,
                document_type="paper",
                return_hypothetical=True
            )
            
            print(f"âœ… HyDE RAG å®Œæˆ")
            print(f"   å‡è¨­æ€§æ–‡æª”ç”Ÿæˆ: {hyde_result.get('hypothetical_time', 0):.2f}s")
            print(f"   æª¢ç´¢è€—æ™‚: {hyde_result.get('retrieval_time', 0):.2f}s")
            print(f"   ç”Ÿæˆè€—æ™‚: {hyde_result.get('answer_time', 0):.2f}s")
            print(f"   ç¸½è€—æ™‚: {hyde_result['total_time']:.2f}s")
            print(f"   æ‰¾åˆ°æ–‡æª”æ•¸: {hyde_result['total_docs_found']}")
            
            if hyde_result.get('hypothetical_document'):
                print(f"\n   ç”Ÿæˆçš„å‡è¨­æ€§æ–‡æª”:")
                hypo_doc = hyde_result['hypothetical_document']
                print(f"   {hypo_doc[:200]}...")
                print(f"   (å®Œæ•´é•·åº¦: {len(hypo_doc)} å­—ç¬¦)")
            
            # é¡¯ç¤ºæª¢ç´¢çµæœ
            print(f"\n   æª¢ç´¢åˆ°çš„æ–‡æª” (å‰ 3 å€‹):")
            for i, doc in enumerate(hyde_result['results'][:3], 1):
                score = doc.get('score', 0)
                title = doc['metadata'].get('title', 'N/A')
                if len(title) > 50:
                    title = title[:47] + "..."
                print(f"   {i}. {title} (åˆ†æ•¸: {score:.4f})")
            
        except Exception as e:
            print(f"âŒ HyDE RAG å‡ºéŒ¯: {e}")
            hyde_result = None
            import traceback
            traceback.print_exc()
        
        # === å°æ¯”ç¸½çµ ===
        print("\n" + "-" * 60)
        print("[å°æ¯”ç¸½çµ]")
        print("-" * 60)
        
        if normal_answer and hyde_result:
            print(f"\nğŸ“Š æ€§èƒ½å°æ¯”:")
            print(f"   æ­£å¸¸ RAG ç¸½è€—æ™‚: {normal_total_time:.2f}s")
            print(f"   HyDE RAG ç¸½è€—æ™‚: {hyde_result['total_time']:.2f}s")
            time_diff = abs(normal_total_time - hyde_result['total_time'])
            time_ratio = (hyde_result['total_time'] / normal_total_time * 100) if normal_total_time > 0 else 0
            print(f"   æ™‚é–“å·®ç•°: {time_diff:.2f}s (HyDE æ˜¯æ­£å¸¸ RAG çš„ {time_ratio:.1f}%)")
            
            print(f"\nğŸ“š æª¢ç´¢çµæœå°æ¯”:")
            print(f"   æ­£å¸¸ RAG æ–‡æª”æ•¸: {len(normal_results)}")
            print(f"   HyDE RAG æ–‡æª”æ•¸: {hyde_result['total_docs_found']}")
            
            # æª¢æŸ¥æ–‡æª”é‡ç–Šåº¦
            normal_doc_ids = set()
            for doc in normal_results:
                metadata = doc.get('metadata', {})
                if 'arxiv_id' in metadata and 'chunk_index' in metadata:
                    normal_doc_ids.add(f"{metadata['arxiv_id']}_{metadata['chunk_index']}")
                else:
                    import hashlib
                    content = doc.get('content', '')
                    content_hash = hashlib.md5(content.encode()).hexdigest()[:16]
                    normal_doc_ids.add(f"doc_{content_hash}")
            
            hyde_doc_ids = set()
            for doc in hyde_result['results']:
                metadata = doc.get('metadata', {})
                if 'arxiv_id' in metadata and 'chunk_index' in metadata:
                    hyde_doc_ids.add(f"{metadata['arxiv_id']}_{metadata['chunk_index']}")
                else:
                    import hashlib
                    content = doc.get('content', '')
                    content_hash = hashlib.md5(content.encode()).hexdigest()[:16]
                    hyde_doc_ids.add(f"doc_{content_hash}")
            
            overlap = len(normal_doc_ids & hyde_doc_ids)
            total_unique = len(normal_doc_ids | hyde_doc_ids)
            overlap_ratio = overlap / total_unique if total_unique > 0 else 0
            
            print(f"   æ–‡æª”é‡ç–Šæ•¸: {overlap}/{total_unique}")
            print(f"   æ–‡æª”é‡ç–Šç‡: {overlap_ratio:.2%}")
            
            # æ¯”è¼ƒåˆ†æ•¸
            if normal_results and hyde_result['results']:
                normal_avg_score = sum(doc.get('score', 0) for doc in normal_results) / len(normal_results)
                hyde_avg_score = sum(doc.get('score', 0) for doc in hyde_result['results']) / len(hyde_result['results'])
                print(f"\n   å¹³å‡ç›¸é—œæ€§åˆ†æ•¸:")
                print(f"   æ­£å¸¸ RAG: {normal_avg_score:.4f}")
                print(f"   HyDE RAG: {hyde_avg_score:.4f}")
                if hyde_avg_score > normal_avg_score:
                    improvement = ((hyde_avg_score - normal_avg_score) / normal_avg_score * 100) if normal_avg_score > 0 else 0
                    print(f"   HyDE æå‡: +{improvement:.1f}%")
            
            print(f"\nğŸ’¡ è§€å¯Ÿ:")
            if hyde_result['total_docs_found'] > len(normal_results):
                print("   âœ“ HyDE RAG æ‰¾åˆ°äº†æ›´å¤šæ–‡æª”")
            elif hyde_result['total_docs_found'] < len(normal_results):
                print("   - æ­£å¸¸ RAG æ‰¾åˆ°äº†æ›´å¤šæ–‡æª”")
            else:
                print("   = å…©ç¨®æ–¹æ³•æ‰¾åˆ°çš„æ–‡æª”æ•¸é‡ç›¸åŒ")
            
            if overlap_ratio < 0.5:
                print("   âœ“ å…©ç¨®æ–¹æ³•æ‰¾åˆ°çš„æ–‡æª”å·®ç•°è¼ƒå¤§ï¼ˆHyDE å¯èƒ½æ‰¾åˆ°äº†ä¸åŒçš„ç›¸é—œæ–‡æª”ï¼‰")
            elif overlap_ratio > 0.8:
                print("   = å…©ç¨®æ–¹æ³•æ‰¾åˆ°çš„æ–‡æª”é«˜åº¦é‡ç–Š")
            else:
                print("   ~ å…©ç¨®æ–¹æ³•æ‰¾åˆ°çš„æ–‡æª”æœ‰éƒ¨åˆ†é‡ç–Š")
            
            if hyde_result['total_time'] > normal_total_time * 1.2:
                print(f"   âš  HyDE RAG è€—æ™‚è¼ƒé•·ï¼ˆå› ç‚ºéœ€è¦ç”Ÿæˆå‡è¨­æ€§æ–‡æª”ï¼‰")
            elif hyde_result['total_time'] < normal_total_time:
                print("   âœ“ HyDE RAG è€—æ™‚æ›´çŸ­")
            else:
                print("   = å…©ç¨®æ–¹æ³•è€—æ™‚ç›¸è¿‘")
            
            # é¡¯ç¤ºç­”æ¡ˆé•·åº¦å°æ¯”
            normal_answer_len = len(normal_answer) if normal_answer else 0
            hyde_answer_len = len(hyde_result.get('answer', ''))
            print(f"\nğŸ“ ç­”æ¡ˆé•·åº¦å°æ¯”:")
            print(f"   æ­£å¸¸ RAG ç­”æ¡ˆé•·åº¦: {normal_answer_len} å­—ç¬¦")
            print(f"   HyDE RAG ç­”æ¡ˆé•·åº¦: {hyde_answer_len} å­—ç¬¦")
        
        print("\n" + "=" * 60)


def test_hyde_basic():
    """åŸºæœ¬ HyDE åŠŸèƒ½æ¸¬è©¦"""
    print("=" * 60)
    print("HyDE RAG åŸºæœ¬åŠŸèƒ½æ¸¬è©¦")
    print("=" * 60)
    
    # åˆå§‹åŒ–ç³»çµ±ï¼ˆèˆ‡å°æ¯”æ¸¬è©¦ç›¸åŒï¼‰
    processor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)
    papers = processor.fetch_papers(
        query="cat:cs.AI OR cat:cs.LG",
        max_results=10
    )
    documents = processor.process_documents(papers)
    
    vector_retriever = VectorRetriever(
        documents,
        embedding_model="sentence-transformers/all-MiniLM-L6-v2",
        persist_directory="./chroma_db_hyde_basic"
    )
    
    hybrid_search = HybridSearch(
        sparse_retriever=BM25Retriever(documents),
        dense_retriever=vector_retriever,
        fusion_method="rrf"
    )
    
    rag_pipeline = RAGPipeline(
        hybrid_search=hybrid_search,
        reranker=Reranker(),
        recall_k=25
    )
    
    llm = OllamaLLM(model_name="llama3.2:3b", timeout=180)
    formatter = PromptFormatter()
    
    hyde_rag = HyDERAG(
        rag_pipeline=rag_pipeline,
        vector_retriever=vector_retriever,
        llm=llm
    )
    
    # æ¸¬è©¦æŸ¥è©¢
    question = "ä»€éº¼æ˜¯å€å¡Šéˆçš„å…±è­˜æ©Ÿåˆ¶ï¼Ÿ"
    print(f"\næ¸¬è©¦æŸ¥è©¢: '{question}'")
    print("-" * 60)
    
    result = hyde_rag.generate_answer(
        question=question,
        formatter=formatter,
        top_k=5,
        return_hypothetical=True
    )
    
    print(f"\nğŸ“Š çµæœ:")
    print(f"   ç¸½è€—æ™‚: {result['total_time']:.2f}s")
    print(f"   æ‰¾åˆ°æ–‡æª”æ•¸: {result['total_docs_found']}")
    
    if result.get('hypothetical_document'):
        print(f"\nğŸ” ç”Ÿæˆçš„å‡è¨­æ€§æ–‡æª”:")
        print("-" * 40)
        print(result['hypothetical_document'])
        print("-" * 40)
    
    print(f"\nğŸ“š æª¢ç´¢åˆ°çš„æ–‡æª”:")
    for i, doc in enumerate(result['results'][:3], 1):
        print(f"\n   {i}. {doc['metadata'].get('title', 'N/A')}")
        print(f"      åˆ†æ•¸: {doc.get('score', 0):.4f}")
        print(f"      å…§å®¹é è¦½: {doc['content'][:150]}...")
    
    print(f"\nğŸ¤– ç”Ÿæˆçš„å›ç­”:")
    print("-" * 40)
    print(result['answer'])
    print("-" * 40)


def test_hybrid_vs_all_methods():
    """å°æ¯”æ¸¬è©¦ï¼šèåˆæ–¹æ³• vs æ‰€æœ‰å–®ç¨æ–¹æ³•"""
    print("=" * 60)
    print("èåˆæ–¹æ³•å°æ¯”æ¸¬è©¦ï¼šHybrid (Sub-query + HyDE) vs æ‰€æœ‰æ–¹æ³•")
    print("=" * 60)
    
    # 1. åˆå§‹åŒ–ç³»çµ±
    print("\n[åˆå§‹åŒ–ç³»çµ±]")
    processor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)
    
    print("å¾ arXiv ç²å–è«–æ–‡...")
    papers = processor.fetch_papers(
        query="cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
        max_results=20
    )
    print(f"âœ… ç²å–äº† {len(papers)} ç¯‡è«–æ–‡")
    
    documents = processor.process_documents(papers)
    print(f"âœ… ç¸½å…±å‰µå»ºäº† {len(documents)} å€‹æ–‡æª” chunks")
    
    # åˆå§‹åŒ–æª¢ç´¢å™¨
    print("åˆå§‹åŒ–æª¢ç´¢å™¨...")
    bm25_retriever = BM25Retriever(documents)
    vector_retriever = VectorRetriever(
        documents,
        embedding_model="sentence-transformers/all-MiniLM-L6-v2",
        persist_directory="./chroma_db_hybrid"
    )
    hybrid_search = HybridSearch(
        sparse_retriever=bm25_retriever,
        dense_retriever=vector_retriever,
        fusion_method="rrf",
        rrf_k=60
    )
    
    reranker = Reranker(
        model_name="BAAI/bge-reranker-base",
        device=None,
        batch_size=16
    )
    rag_pipeline = RAGPipeline(
        hybrid_search=hybrid_search,
        reranker=reranker,
        recall_k=25,
        adaptive_recall=True
    )
    
    # åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨
    print("åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨...")
    try:
        llm = OllamaLLM(model_name="llama3.2:3b", timeout=180)
        print(f"âœ… LLM åˆå§‹åŒ–å®Œæˆ: {llm.model_name}")
    except Exception as e:
        print(f"âš ï¸  LLM åˆå§‹åŒ–å¤±æ•—: {e}")
        print("è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œä¸¦å·²ä¸‹è¼‰æ¨¡å‹")
        return
    
    formatter = PromptFormatter(
        include_metadata=True,
        format_style="detailed"
    )
    
    # åˆå§‹åŒ–æ‰€æœ‰æ–¹æ³•
    print("åˆå§‹åŒ–æ‰€æœ‰ RAG æ–¹æ³•...")
    subquery_rag = SubQueryDecompositionRAG(
        rag_pipeline=rag_pipeline,
        llm=llm,
        max_sub_queries=3,
        top_k_per_subquery=5,
        enable_parallel=True
    )
    
    hyde_rag = HyDERAG(
        rag_pipeline=rag_pipeline,
        vector_retriever=vector_retriever,
        llm=llm,
        hypothetical_length=200,
        temperature=0.7
    )
    
    hybrid_rag = HybridSubqueryHyDERAG(
        rag_pipeline=rag_pipeline,
        vector_retriever=vector_retriever,
        llm=llm,
        max_sub_queries=3,
        top_k_per_subquery=5,
        hypothetical_length=200,
        temperature_subquery=0.3,
        temperature_hyde=0.7,
        enable_parallel=True
    )
    print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
    
    # 2. æ¸¬è©¦æŸ¥è©¢
    test_queries = [
        "transformer architecture, attention mechanism, and optimization techniques",
        "æ¯”è¼ƒæ·±åº¦å­¸ç¿’å’Œæ©Ÿå™¨å­¸ç¿’çš„å·®ç•°ã€å„ªç¼ºé»å’Œæ‡‰ç”¨å ´æ™¯",
    ]
    
    print("\n" + "=" * 60)
    print("é–‹å§‹å°æ¯”æ¸¬è©¦")
    print("=" * 60)
    
    for query in test_queries:
        print("\n" + "=" * 60)
        print(f"æ¸¬è©¦æŸ¥è©¢: '{query}'")
        print("=" * 60)
        
        results = {}
        
        # === æ–¹æ³• 1: æ­£å¸¸ RAG ===
        print("\n[æ–¹æ³• 1] æ­£å¸¸ RAG")
        print("-" * 60)
        try:
            normal_start = time.time()
            normal_results = vector_retriever.retrieve(query=query, top_k=5)
            normal_time = time.time() - normal_start
            results['normal'] = {
                'docs': normal_results,
                'time': normal_time,
                'count': len(normal_results)
            }
            print(f"âœ… æ‰¾åˆ° {len(normal_results)} å€‹æ–‡æª”ï¼Œè€—æ™‚ {normal_time:.2f}s")
        except Exception as e:
            print(f"âŒ å‡ºéŒ¯: {e}")
            results['normal'] = {'docs': [], 'time': 0, 'count': 0}
        
        # === æ–¹æ³• 2: Sub-query RAG ===
        print("\n[æ–¹æ³• 2] Sub-query Decomposition RAG")
        print("-" * 60)
        try:
            subquery_result = subquery_rag.query(
                question=query,
                top_k=5,
                return_sub_queries=True
            )
            results['subquery'] = {
                'docs': subquery_result['results'],
                'time': subquery_result['elapsed_time'],
                'count': subquery_result['total_docs_found'],
                'sub_queries': subquery_result.get('sub_queries', [])
            }
            print(f"âœ… æ‰¾åˆ° {subquery_result['total_docs_found']} å€‹æ–‡æª”ï¼Œè€—æ™‚ {subquery_result['elapsed_time']:.2f}s")
            if subquery_result.get('sub_queries'):
                print(f"   å­å•é¡Œæ•¸: {len(subquery_result['sub_queries'])}")
        except Exception as e:
            print(f"âŒ å‡ºéŒ¯: {e}")
            results['subquery'] = {'docs': [], 'time': 0, 'count': 0, 'sub_queries': []}
        
        # === æ–¹æ³• 3: HyDE RAG ===
        print("\n[æ–¹æ³• 3] HyDE RAG")
        print("-" * 60)
        try:
            hyde_result = hyde_rag.query(
                question=query,
                top_k=5,
                return_hypothetical=True
            )
            results['hyde'] = {
                'docs': hyde_result['results'],
                'time': hyde_result['elapsed_time'],
                'count': hyde_result['total_docs_found'],
                'hypothetical': hyde_result.get('hypothetical_document', '')
            }
            print(f"âœ… æ‰¾åˆ° {hyde_result['total_docs_found']} å€‹æ–‡æª”ï¼Œè€—æ™‚ {hyde_result['elapsed_time']:.2f}s")
        except Exception as e:
            print(f"âŒ å‡ºéŒ¯: {e}")
            results['hyde'] = {'docs': [], 'time': 0, 'count': 0, 'hypothetical': ''}
        
        # === æ–¹æ³• 4: Hybrid (Sub-query + HyDE) RAG ===
        print("\n[æ–¹æ³• 4] Hybrid (Sub-query + HyDE) RAG")
        print("-" * 60)
        try:
            hybrid_result = hybrid_rag.query(
                question=query,
                top_k=5,
                return_sub_queries=True,
                return_hypothetical=True
            )
            results['hybrid'] = {
                'docs': hybrid_result['results'],
                'time': hybrid_result['elapsed_time'],
                'count': hybrid_result['total_docs_found'],
                'sub_queries': hybrid_result.get('sub_queries', []),
                'hypothetical': hybrid_result.get('hypothetical_documents', {})
            }
            print(f"âœ… æ‰¾åˆ° {hybrid_result['total_docs_found']} å€‹æ–‡æª”ï¼Œè€—æ™‚ {hybrid_result['elapsed_time']:.2f}s")
            if hybrid_result.get('sub_queries'):
                print(f"   å­å•é¡Œæ•¸: {len(hybrid_result['sub_queries'])}")
        except Exception as e:
            print(f"âŒ å‡ºéŒ¯: {e}")
            import traceback
            traceback.print_exc()
            results['hybrid'] = {'docs': [], 'time': 0, 'count': 0, 'sub_queries': [], 'hypothetical': {}}
        
        # === å°æ¯”ç¸½çµ ===
        print("\n" + "-" * 60)
        print("[å°æ¯”ç¸½çµ]")
        print("-" * 60)
        
        print(f"\nğŸ“Š æ€§èƒ½å°æ¯”:")
        for method_name, method_result in results.items():
            method_display = {
                'normal': 'æ­£å¸¸ RAG',
                'subquery': 'Sub-query RAG',
                'hyde': 'HyDE RAG',
                'hybrid': 'Hybrid RAG'
            }.get(method_name, method_name)
            print(f"   {method_display}: {method_result['time']:.2f}s, {method_result['count']} å€‹æ–‡æª”")
        
        # æ¯”è¼ƒå¹³å‡åˆ†æ•¸
        print(f"\nğŸ“ˆ å¹³å‡ç›¸é—œæ€§åˆ†æ•¸:")
        for method_name, method_result in results.items():
            if method_result['docs']:
                avg_score = sum(doc.get('score', 0) for doc in method_result['docs']) / len(method_result['docs'])
                method_display = {
                    'normal': 'æ­£å¸¸ RAG',
                    'subquery': 'Sub-query RAG',
                    'hyde': 'HyDE RAG',
                    'hybrid': 'Hybrid RAG'
                }.get(method_name, method_name)
                print(f"   {method_display}: {avg_score:.4f}")
        
        # æ–‡æª”é‡ç–Šåˆ†æ
        print(f"\nğŸ“š æ–‡æª”é‡ç–Šåˆ†æ:")
        if results['hybrid']['docs']:
            # ç²å– Hybrid æ–¹æ³•çš„æ–‡æª” ID
            hybrid_doc_ids = set()
            for doc in results['hybrid']['docs']:
                metadata = doc.get('metadata', {})
                if 'arxiv_id' in metadata and 'chunk_index' in metadata:
                    hybrid_doc_ids.add(f"{metadata['arxiv_id']}_{metadata['chunk_index']}")
            
            # èˆ‡å…¶ä»–æ–¹æ³•æ¯”è¼ƒ
            for method_name in ['normal', 'subquery', 'hyde']:
                if results[method_name]['docs']:
                    method_doc_ids = set()
                    for doc in results[method_name]['docs']:
                        metadata = doc.get('metadata', {})
                        if 'arxiv_id' in metadata and 'chunk_index' in metadata:
                            method_doc_ids.add(f"{metadata['arxiv_id']}_{metadata['chunk_index']}")
                    
                    overlap = len(hybrid_doc_ids & method_doc_ids)
                    method_display = {
                        'normal': 'æ­£å¸¸ RAG',
                        'subquery': 'Sub-query RAG',
                        'hyde': 'HyDE RAG'
                    }.get(method_name, method_name)
                    print(f"   Hybrid vs {method_display}: {overlap} å€‹é‡ç–Š")
        
        print(f"\nğŸ’¡ è§€å¯Ÿ:")
        hybrid_count = results['hybrid']['count']
        hybrid_time = results['hybrid']['time']
        
        if hybrid_count >= max(r['count'] for r in results.values() if r['count'] > 0):
            print("   âœ“ Hybrid æ–¹æ³•æ‰¾åˆ°äº†æœ€å¤šæˆ–æœ€å¤šçš„æ–‡æª”")
        
        if hybrid_time > max(r['time'] for r in results.values() if r['time'] > 0) * 0.8:
            print("   âš  Hybrid æ–¹æ³•è€—æ™‚è¼ƒé•·ï¼ˆå› ç‚ºçµåˆäº†å…©ç¨®æ–¹æ³•ï¼‰")
        else:
            print("   âœ“ Hybrid æ–¹æ³•æ€§èƒ½å¯æ¥å—")
        
        print("\n" + "=" * 60)


def evaluate_answer_quality(answer: str, query: str) -> dict:
    """
    è©•ä¼°ç­”æ¡ˆè³ªé‡
    
    Args:
        answer: ç”Ÿæˆçš„ç­”æ¡ˆ
        query: åŸå§‹å•é¡Œ
        
    Returns:
        åŒ…å«å„é …è©•åˆ†çš„å­—å…¸
    """
    query_keywords = set(query.lower().split())
    answer_lower = answer.lower()
    
    # é—œéµè©è¦†è“‹ç‡
    matched = sum(1 for kw in query_keywords if kw in answer_lower)
    keyword_coverage = matched / len(query_keywords) if query_keywords else 0
    
    # ç­”æ¡ˆè©³ç´°ç¨‹åº¦ï¼ˆé•·åº¦ï¼‰
    detail_score = min(len(answer) / 500, 1.0)  # 500 å­—ç¬¦ç‚ºæ»¿åˆ†
    
    # å°ˆæ¥­è¡“èªæ•¸é‡ï¼ˆç°¡å–®å•Ÿç™¼å¼ï¼‰
    technical_terms = ['algorithm', 'mechanism', 'architecture', 'optimization', 
                      'technique', 'method', 'model', 'system', 'process',
                      'ç®—æ³•', 'æ©Ÿåˆ¶', 'æ¶æ§‹', 'å„ªåŒ–', 'æŠ€è¡“', 'æ–¹æ³•', 'æ¨¡å‹', 'ç³»çµ±']
    tech_count = sum(1 for term in technical_terms if term in answer_lower)
    tech_score = min(tech_count / 5, 1.0)
    
    overall_score = (keyword_coverage * 0.4 + detail_score * 0.3 + tech_score * 0.3)
    
    return {
        'keyword_coverage': keyword_coverage,
        'detail_score': detail_score,
        'tech_score': tech_score,
        'overall_score': overall_score
    }


def test_visual_comparison_with_answers():
    """è¦–è¦ºåŒ–å°æ¯”æ¸¬è©¦ï¼šåŒ…å«å¯¦éš›ç­”æ¡ˆï¼Œè®“ç”¨æˆ¶ç›´è§€æ„Ÿå—å·®ç•°"""
    print("=" * 80)
    print("ğŸ¯ è¦–è¦ºåŒ– RAG å°æ¯”æ¸¬è©¦ - è®“ä½ ç›´è§€æ„Ÿå—å“ªå€‹æ›´å¥½ï¼")
    print("=" * 80)
    
    # 1. åˆå§‹åŒ–ç³»çµ±
    print("\n[åˆå§‹åŒ–ç³»çµ±]")
    processor = DocumentProcessor(chunk_size=1000, chunk_overlap=200)
    
    print("å¾ arXiv ç²å–è«–æ–‡...")
    papers = processor.fetch_papers(
        query="cat:cs.AI OR cat:cs.LG OR cat:cs.CL",
        max_results=20
    )
    print(f"âœ… ç²å–äº† {len(papers)} ç¯‡è«–æ–‡")
    
    documents = processor.process_documents(papers)
    print(f"âœ… ç¸½å…±å‰µå»ºäº† {len(documents)} å€‹æ–‡æª” chunks")
    
    # åˆå§‹åŒ–æª¢ç´¢å™¨
    print("åˆå§‹åŒ–æª¢ç´¢å™¨...")
    bm25_retriever = BM25Retriever(documents)
    vector_retriever = VectorRetriever(
        documents,
        embedding_model="sentence-transformers/all-MiniLM-L6-v2",
        persist_directory="./chroma_db_visual"
    )
    hybrid_search = HybridSearch(
        sparse_retriever=bm25_retriever,
        dense_retriever=vector_retriever,
        fusion_method="rrf",
        rrf_k=60
    )
    
    reranker = Reranker(
        model_name="BAAI/bge-reranker-base",
        device=None,
        batch_size=16
    )
    rag_pipeline = RAGPipeline(
        hybrid_search=hybrid_search,
        reranker=reranker,
        recall_k=25,
        adaptive_recall=True
    )
    
    # åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨
    print("åˆå§‹åŒ– LLM å’Œæ ¼å¼åŒ–å™¨...")
    try:
        llm = OllamaLLM(model_name="llama3.2:3b", timeout=180)
        print(f"âœ… LLM åˆå§‹åŒ–å®Œæˆ: {llm.model_name}")
    except Exception as e:
        print(f"âš ï¸  LLM åˆå§‹åŒ–å¤±æ•—: {e}")
        print("è«‹ç¢ºä¿ Ollama æ­£åœ¨é‹è¡Œä¸¦å·²ä¸‹è¼‰æ¨¡å‹")
        return
    
    formatter = PromptFormatter(
        include_metadata=True,
        format_style="detailed"
    )
    
    # åˆå§‹åŒ–æ‰€æœ‰æ–¹æ³•
    print("åˆå§‹åŒ–æ‰€æœ‰ RAG æ–¹æ³•...")
    subquery_rag = SubQueryDecompositionRAG(
        rag_pipeline=rag_pipeline,
        llm=llm,
        max_sub_queries=3,
        top_k_per_subquery=5,
        enable_parallel=True
    )
    
    hyde_rag = HyDERAG(
        rag_pipeline=rag_pipeline,
        vector_retriever=vector_retriever,
        llm=llm,
        hypothetical_length=200,
        temperature=0.7
    )
    
    hybrid_rag = HybridSubqueryHyDERAG(
        rag_pipeline=rag_pipeline,
        vector_retriever=vector_retriever,
        llm=llm,
        max_sub_queries=3,
        top_k_per_subquery=5,
        hypothetical_length=200,
        temperature_subquery=0.3,
        temperature_hyde=0.7,
        enable_parallel=True
    )
    print("âœ… ç³»çµ±åˆå§‹åŒ–å®Œæˆï¼")
    
    # 2. æ¸¬è©¦æŸ¥è©¢
    test_query = "transformer architecture and attention mechanism"
    
    print("\n" + "=" * 80)
    print(f"ğŸ“ æ¸¬è©¦å•é¡Œ: '{test_query}'")
    print("=" * 80)
    
    methods_results = {}
    
    # === æ–¹æ³• 1: æ­£å¸¸ RAG ===
    print("\n" + "ğŸ”µ" * 40)
    print("ã€æ–¹æ³• 1ã€‘æ­£å¸¸ RAG")
    print("ğŸ”µ" * 40)
    try:
        normal_start = time.time()
        normal_docs = vector_retriever.retrieve(query=test_query, top_k=3)
        normal_retrieval_time = time.time() - normal_start
        
        print(f"\nğŸ“š æª¢ç´¢åˆ°çš„æ–‡æª”ï¼ˆå‰ 3 å€‹ï¼‰:")
        for i, doc in enumerate(normal_docs, 1):
            score = doc.get('score', 0)
            title = doc['metadata'].get('title', 'N/A')
            print(f"\n  {i}. ğŸ“„ {title[:70]}")
            print(f"     ç›¸é—œæ€§: {'â­' * int(score * 5)} ({score:.3f})")
            print(f"     å…§å®¹é è¦½: {doc['content'][:200]}...")
        
        # ç”Ÿæˆç­”æ¡ˆ
        normal_context = formatter.format_context(normal_docs, document_type="paper")
        normal_prompt = formatter.create_prompt(test_query, normal_context, document_type="paper")
        normal_answer_start = time.time()
        normal_answer = llm.generate(prompt=normal_prompt, temperature=0.7, max_tokens=500)
        normal_answer_time = time.time() - normal_answer_start
        normal_total_time = time.time() - normal_start
        
        print(f"\nğŸ’¬ ç”Ÿæˆçš„ç­”æ¡ˆ:")
        print("-" * 60)
        print(normal_answer[:600])
        if len(normal_answer) > 600:
            print("...")
        print("-" * 60)
        
        # è©•ä¼°ç­”æ¡ˆè³ªé‡
        normal_quality = evaluate_answer_quality(normal_answer, test_query)
        normal_avg_score = sum(doc.get('score', 0) for doc in normal_docs) / len(normal_docs) if normal_docs else 0
        
        methods_results['æ­£å¸¸ RAG'] = {
            'docs': normal_docs,
            'count': len(normal_docs),
            'avg_score': normal_avg_score,
            'answer': normal_answer,
            'time': normal_total_time,
            'quality': normal_quality
        }
        
    except Exception as e:
        print(f"âŒ å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        methods_results['æ­£å¸¸ RAG'] = {'docs': [], 'count': 0, 'avg_score': 0, 'answer': '', 'time': 0, 'quality': {}}
    
    # === æ–¹æ³• 2: Sub-query RAG ===
    print("\n" + "ğŸŸ¢" * 40)
    print("ã€æ–¹æ³• 2ã€‘Sub-query Decomposition RAG")
    print("ğŸŸ¢" * 40)
    try:
        subquery_result = subquery_rag.query(question=test_query, top_k=3, return_sub_queries=True)
        
        if subquery_result.get('sub_queries'):
            print(f"\nğŸ” æ‹†è§£çš„å­å•é¡Œ:")
            for i, sq in enumerate(subquery_result['sub_queries'], 1):
                print(f"   {i}. {sq}")
        
        print(f"\nğŸ“š æª¢ç´¢åˆ°çš„æ–‡æª”ï¼ˆå‰ 3 å€‹ï¼‰:")
        for i, doc in enumerate(subquery_result['results'], 1):
            score = doc.get('rerank_score', doc.get('hybrid_score', doc.get('score', 0)))
            title = doc['metadata'].get('title', 'N/A')
            print(f"\n  {i}. ğŸ“„ {title[:70]}")
            print(f"     ç›¸é—œæ€§: {'â­' * int(score * 5)} ({score:.3f})")
            print(f"     å…§å®¹é è¦½: {doc['content'][:200]}...")
        
        # ç”Ÿæˆç­”æ¡ˆ
        subquery_context = formatter.format_context(subquery_result['results'], document_type="paper")
        subquery_prompt = formatter.create_prompt(test_query, subquery_context, document_type="paper")
        subquery_answer = llm.generate(prompt=subquery_prompt, temperature=0.7, max_tokens=500)
        
        print(f"\nğŸ’¬ ç”Ÿæˆçš„ç­”æ¡ˆ:")
        print("-" * 60)
        print(subquery_answer[:600])
        if len(subquery_answer) > 600:
            print("...")
        print("-" * 60)
        
        # è©•ä¼°ç­”æ¡ˆè³ªé‡
        subquery_quality = evaluate_answer_quality(subquery_answer, test_query)
        subquery_avg_score = sum(doc.get('rerank_score', doc.get('hybrid_score', doc.get('score', 0))) 
                                 for doc in subquery_result['results']) / len(subquery_result['results']) if subquery_result['results'] else 0
        
        methods_results['Sub-query RAG'] = {
            'docs': subquery_result['results'],
            'count': subquery_result['total_docs_found'],
            'avg_score': subquery_avg_score,
            'answer': subquery_answer,
            'time': subquery_result['elapsed_time'],
            'quality': subquery_quality,
            'sub_queries': subquery_result.get('sub_queries', [])
        }
        
    except Exception as e:
        print(f"âŒ å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        methods_results['Sub-query RAG'] = {'docs': [], 'count': 0, 'avg_score': 0, 'answer': '', 'time': 0, 'quality': {}}
    
    # === æ–¹æ³• 3: HyDE RAG ===
    print("\n" + "ğŸŸ¡" * 40)
    print("ã€æ–¹æ³• 3ã€‘HyDE RAG")
    print("ğŸŸ¡" * 40)
    try:
        hyde_result = hyde_rag.query(question=test_query, top_k=3, return_hypothetical=True)
        
        if hyde_result.get('hypothetical_document'):
            print(f"\nğŸ“ ç”Ÿæˆçš„å‡è¨­æ€§æ–‡æª”:")
            print("-" * 60)
            print(hyde_result['hypothetical_document'][:300])
            print("-" * 60)
        
        print(f"\nğŸ“š æª¢ç´¢åˆ°çš„æ–‡æª”ï¼ˆå‰ 3 å€‹ï¼‰:")
        for i, doc in enumerate(hyde_result['results'], 1):
            score = doc.get('score', 0)
            title = doc['metadata'].get('title', 'N/A')
            print(f"\n  {i}. ğŸ“„ {title[:70]}")
            print(f"     ç›¸é—œæ€§: {'â­' * int(score * 5)} ({score:.3f})")
            print(f"     å…§å®¹é è¦½: {doc['content'][:200]}...")
        
        # ç”Ÿæˆç­”æ¡ˆ
        hyde_context = formatter.format_context(hyde_result['results'], document_type="paper")
        hyde_prompt = formatter.create_prompt(test_query, hyde_context, document_type="paper")
        hyde_answer = llm.generate(prompt=hyde_prompt, temperature=0.7, max_tokens=500)
        
        print(f"\nğŸ’¬ ç”Ÿæˆçš„ç­”æ¡ˆ:")
        print("-" * 60)
        print(hyde_answer[:600])
        if len(hyde_answer) > 600:
            print("...")
        print("-" * 60)
        
        # è©•ä¼°ç­”æ¡ˆè³ªé‡
        hyde_quality = evaluate_answer_quality(hyde_answer, test_query)
        hyde_avg_score = sum(doc.get('score', 0) for doc in hyde_result['results']) / len(hyde_result['results']) if hyde_result['results'] else 0
        
        methods_results['HyDE RAG'] = {
            'docs': hyde_result['results'],
            'count': hyde_result['total_docs_found'],
            'avg_score': hyde_avg_score,
            'answer': hyde_answer,
            'time': hyde_result['elapsed_time'],
            'quality': hyde_quality,
            'hypothetical': hyde_result.get('hypothetical_document', '')
        }
        
    except Exception as e:
        print(f"âŒ å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        methods_results['HyDE RAG'] = {'docs': [], 'count': 0, 'avg_score': 0, 'answer': '', 'time': 0, 'quality': {}}
    
    # === æ–¹æ³• 4: Hybrid RAG ===
    print("\n" + "ğŸŸ£" * 40)
    print("ã€æ–¹æ³• 4ã€‘Hybrid (Sub-query + HyDE) RAG")
    print("ğŸŸ£" * 40)
    try:
        hybrid_result = hybrid_rag.query(
            question=test_query, 
            top_k=3, 
            return_sub_queries=True,
            return_hypothetical=True
        )
        
        if hybrid_result.get('sub_queries'):
            print(f"\nğŸ” æ‹†è§£çš„å­å•é¡Œ:")
            for i, sq in enumerate(hybrid_result['sub_queries'], 1):
                print(f"   {i}. {sq}")
        
        if hybrid_result.get('hypothetical_documents'):
            print(f"\nğŸ“ ç‚ºæ¯å€‹å­å•é¡Œç”Ÿæˆçš„å‡è¨­æ€§æ–‡æª”ï¼ˆç¤ºä¾‹ï¼‰:")
            for sq, hypo_doc in list(hybrid_result['hypothetical_documents'].items())[:1]:
                print(f"   å­å•é¡Œ: {sq}")
                print(f"   å‡è¨­æ€§æ–‡æª”: {hypo_doc[:200]}...")
        
        print(f"\nğŸ“š æª¢ç´¢åˆ°çš„æ–‡æª”ï¼ˆå‰ 3 å€‹ï¼‰:")
        for i, doc in enumerate(hybrid_result['results'], 1):
            score = doc.get('score', 0)
            title = doc['metadata'].get('title', 'N/A')
            print(f"\n  {i}. ğŸ“„ {title[:70]}")
            print(f"     ç›¸é—œæ€§: {'â­' * int(score * 5)} ({score:.3f})")
            print(f"     å…§å®¹é è¦½: {doc['content'][:200]}...")
        
        # ç”Ÿæˆç­”æ¡ˆ
        hybrid_context = formatter.format_context(hybrid_result['results'], document_type="paper")
        hybrid_prompt = formatter.create_prompt(test_query, hybrid_context, document_type="paper")
        hybrid_answer = llm.generate(prompt=hybrid_prompt, temperature=0.7, max_tokens=500)
        
        print(f"\nğŸ’¬ ç”Ÿæˆçš„ç­”æ¡ˆ:")
        print("-" * 60)
        print(hybrid_answer[:600])
        if len(hybrid_answer) > 600:
            print("...")
        print("-" * 60)
        
        # è©•ä¼°ç­”æ¡ˆè³ªé‡
        hybrid_quality = evaluate_answer_quality(hybrid_answer, test_query)
        hybrid_avg_score = sum(doc.get('score', 0) for doc in hybrid_result['results']) / len(hybrid_result['results']) if hybrid_result['results'] else 0
        
        methods_results['Hybrid RAG'] = {
            'docs': hybrid_result['results'],
            'count': hybrid_result['total_docs_found'],
            'avg_score': hybrid_avg_score,
            'answer': hybrid_answer,
            'time': hybrid_result['elapsed_time'],
            'quality': hybrid_quality,
            'sub_queries': hybrid_result.get('sub_queries', []),
            'hypothetical': hybrid_result.get('hypothetical_documents', {})
        }
        
    except Exception as e:
        print(f"âŒ å‡ºéŒ¯: {e}")
        import traceback
        traceback.print_exc()
        methods_results['Hybrid RAG'] = {'docs': [], 'count': 0, 'avg_score': 0, 'answer': '', 'time': 0, 'quality': {}}
    
    # === ç¶œåˆå°æ¯”ç¸½çµ ===
    print("\n" + "=" * 80)
    print("ğŸ“Š ç¶œåˆå°æ¯”ç¸½çµ")
    print("=" * 80)
    
    # 1. æ€§èƒ½å°æ¯”è¡¨
    print(f"\nğŸ“ˆ æ€§èƒ½å°æ¯”è¡¨:")
    print(f"{'æ–¹æ³•':<25} {'æ–‡æª”æ•¸':<10} {'å¹³å‡åˆ†æ•¸':<12} {'ç­”æ¡ˆé•·åº¦':<12} {'è€—æ™‚':<10}")
    print("-" * 80)
    for method_name, result in methods_results.items():
        print(f"{method_name:<25} {result['count']:<10} {result['avg_score']:<12.3f} "
              f"{len(result.get('answer', '')):<12} {result.get('time', 0):<10.2f}s")
    
    # 2. ç­”æ¡ˆè³ªé‡è©•åˆ†
    print(f"\nâ­ ç­”æ¡ˆè³ªé‡è©•åˆ†:")
    for method_name, result in methods_results.items():
        quality = result.get('quality', {})
        if quality:
            overall = quality.get('overall_score', 0)
            stars = "â­" * int(overall * 10)  # 0-10 æ˜Ÿ
            print(f"   {method_name:<25} {stars} ({overall:.2f})")
            print(f"      - é—œéµè©è¦†è“‹: {quality.get('keyword_coverage', 0):.1%}")
            print(f"      - è©³ç´°ç¨‹åº¦: {quality.get('detail_score', 0):.1%}")
            print(f"      - å°ˆæ¥­è¡“èª: {quality.get('tech_score', 0):.1%}")
    
    # 3. é—œéµè©åŒ¹é…åˆ†æ
    query_keywords = set(test_query.lower().split())
    print(f"\nğŸ”‘ é—œéµè©åŒ¹é…åˆ†æï¼ˆå•é¡Œé—œéµè©: {', '.join(query_keywords)}ï¼‰:")
    for method_name, result in methods_results.items():
        answer = result.get('answer', '')
        if answer:
            answer_lower = answer.lower()
            matched_keywords = [kw for kw in query_keywords if kw in answer_lower]
            match_rate = len(matched_keywords) / len(query_keywords) * 100 if query_keywords else 0
            bars = "â–ˆ" * int(match_rate / 10)  # æ¯ 10% ä¸€å€‹æ–¹å¡Š
            print(f"   {method_name:<25} {bars} {len(matched_keywords)}/{len(query_keywords)} ({match_rate:.0f}%)")
    
    # 4. æ–‡æª”ç›¸é—œæ€§è¦–è¦ºåŒ–
    print(f"\nâ­ æ–‡æª”ç›¸é—œæ€§å°æ¯”ï¼ˆæ˜Ÿç´šè¶Šé«˜è¶Šç›¸é—œï¼‰:")
    for method_name, result in methods_results.items():
        avg_score = result.get('avg_score', 0)
        stars = "â­" * int(avg_score * 10)  # 0-10 æ˜Ÿ
        print(f"   {method_name:<25} {stars} ({avg_score:.3f})")
    
    # 5. ç­”æ¡ˆè©³ç´°ç¨‹åº¦å°æ¯”
    print(f"\nğŸ“ ç­”æ¡ˆè©³ç´°ç¨‹åº¦å°æ¯”:")
    max_length = max(len(r.get('answer', '')) for r in methods_results.values()) if methods_results else 1
    for method_name, result in methods_results.items():
        length = len(result.get('answer', ''))
        bars = "â–ˆ" * int((length / max_length) * 30) if max_length > 0 else ""  # æœ€å¤š 30 å€‹æ–¹å¡Š
        print(f"   {method_name:<25} {bars} ({length} å­—ç¬¦)")
    
    # 6. æœ€çµ‚å»ºè­°
    print("\n" + "=" * 80)
    print("ğŸ’¡ å¦‚ä½•åˆ¤æ–·å“ªå€‹æœ€å¥½ï¼Ÿ")
    print("=" * 80)
    print("""
    ğŸ“š çœ‹æ–‡æª”ç›¸é—œæ€§ï¼š
       - æª¢æŸ¥æ¯å€‹æ–¹æ³•æ‰¾åˆ°çš„æ–‡æª”æ¨™é¡Œæ˜¯å¦çœŸçš„èˆ‡å•é¡Œç›¸é—œ
       - æŸ¥çœ‹æ–‡æª”å…§å®¹é è¦½ï¼Œçœ‹æ˜¯å¦åŒ…å«å•é¡Œçš„é—œéµä¿¡æ¯
       - æ˜Ÿç´šè¶Šé«˜ï¼Œæ–‡æª”è¶Šç›¸é—œ
    
    ğŸ’¬ çœ‹ç­”æ¡ˆè³ªé‡ï¼š
       - å“ªå€‹ç­”æ¡ˆæ›´æº–ç¢ºåœ°å›ç­”äº†å•é¡Œï¼Ÿ
       - å“ªå€‹ç­”æ¡ˆæ›´è©³ç´°ã€æ›´å®Œæ•´ï¼Ÿ
       - å“ªå€‹ç­”æ¡ˆåŒ…å«æ›´å¤šå°ˆæ¥­è¡“èªå’Œç´°ç¯€ï¼Ÿ
       - é—œéµè©åŒ¹é…ç‡è¶Šé«˜è¶Šå¥½
    
    â±ï¸ çœ‹éŸ¿æ‡‰æ™‚é–“ï¼š
       - å¦‚æœè³ªé‡ç›¸è¿‘ï¼Œé¸æ“‡æ›´å¿«çš„
       - å¦‚æœè³ªé‡å·®ç•°å¤§ï¼Œå„ªå…ˆé¸æ“‡è³ªé‡å¥½çš„
    
    ğŸ† ç¶œåˆå»ºè­°ï¼š
    """)
    
    # æ‰¾å‡ºæœ€ä½³æ–¹æ³•
    best_quality = None
    best_quality_method = None
    best_score = None
    best_score_method = None
    
    for method_name, result in methods_results.items():
        quality = result.get('quality', {})
        if quality:
            overall = quality.get('overall_score', 0)
            if best_quality is None or overall > best_quality:
                best_quality = overall
                best_quality_method = method_name
        
        avg_score = result.get('avg_score', 0)
        if best_score is None or avg_score > best_score:
            best_score = avg_score
            best_score_method = method_name
    
    if best_quality_method:
        print(f"   âœ… ç­”æ¡ˆè³ªé‡æœ€ä½³: {best_quality_method} (è³ªé‡åˆ†æ•¸: {best_quality:.2f})")
    if best_score_method:
        print(f"   âœ… æ–‡æª”ç›¸é—œæ€§æœ€ä½³: {best_score_method} (å¹³å‡åˆ†æ•¸: {best_score:.3f})")
    
    print("\n" + "=" * 80)


def main():
    """ä¸»å‡½æ•¸"""
    import argparse
    
    parser = argparse.ArgumentParser(description="æ¸¬è©¦ HyDE RAG")
    parser.add_argument(
        "--compare",
        action="store_true",
        help="åŸ·è¡Œå°æ¯”æ¸¬è©¦ï¼ˆHyDE vs æ­£å¸¸ RAGï¼‰"
    )
    parser.add_argument(
        "--basic",
        action="store_true",
        help="åŸ·è¡ŒåŸºæœ¬åŠŸèƒ½æ¸¬è©¦"
    )
    parser.add_argument(
        "--hybrid",
        action="store_true",
        help="åŸ·è¡Œèåˆæ–¹æ³•å°æ¯”æ¸¬è©¦ï¼ˆHybrid vs æ‰€æœ‰æ–¹æ³•ï¼‰"
    )
    parser.add_argument(
        "--visual",
        action="store_true",
        help="åŸ·è¡Œè¦–è¦ºåŒ–å°æ¯”æ¸¬è©¦ï¼ˆé¡¯ç¤ºå¯¦éš›å…§å®¹å’Œç­”æ¡ˆï¼Œæœ€ç›´è§€ï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.visual:
        test_visual_comparison_with_answers()
    elif args.hybrid:
        test_hybrid_vs_all_methods()
    elif args.compare:
        test_hyde_vs_normal_rag()
    elif args.basic:
        test_hyde_basic()
    else:
        # é è¨­åŸ·è¡Œè¦–è¦ºåŒ–æ¸¬è©¦ï¼ˆæœ€ç›´è§€ï¼‰
        test_visual_comparison_with_answers()


if __name__ == "__main__":
    main()

