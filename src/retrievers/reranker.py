"""
é‡æ’åºæ¨¡çµ„ï¼šä½¿ç”¨ Cross-Encoder é€²è¡Œç²¾æº–é‡æ’
"""
from typing import List, Dict, Optional, Tuple
from sentence_transformers import CrossEncoder
import time
import logging

# å˜—è©¦å°å…¥ torch ä¾†æª¢æ¸¬å¯ç”¨çš„è¨­å‚™
try:
    import torch
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def get_device() -> str:
    """
    è‡ªå‹•æª¢æ¸¬ä¸¦è¿”å›æœ€ä½³å¯ç”¨çš„è¨­å‚™
    
    Returns:
        è¨­å‚™åç¨±: 'mps' (macOS GPU), 'cuda' (NVIDIA GPU), æˆ– 'cpu'
    """
    if not TORCH_AVAILABLE:
        return 'cpu'
    
    # å„ªå…ˆé †åº: MPS (macOS) > CUDA (NVIDIA) > CPU
    if torch.backends.mps.is_available():
        return 'mps'
    elif torch.cuda.is_available():
        return 'cuda'
    else:
        return 'cpu'


class Reranker:
    """é‡æ’åºçµ„ä»¶ï¼šä½¿ç”¨ Cross-Encoder é€²è¡Œç²¾æº–é‡æ’"""
    
    def __init__(
        self, 
        model_name: str = "BAAI/bge-reranker-base", 
        device: str = None,
        max_length: int = 512,
        batch_size: int = 32,
        enable_cache: bool = True
    ):
        """
        åˆå§‹åŒ– Cross-Encoder æ¨¡å‹
        
        Args:
            model_name: Cross-Encoder æ¨¡å‹åç¨±
            device: è¨­å‚™åç¨± ('cuda', 'cpu', 'mps')
            max_length: æœ€å¤§ token é•·åº¦ï¼ˆæ¨¡å‹é™åˆ¶ï¼‰
            batch_size: æ‰¹è™•ç†å¤§å°ï¼Œç”¨æ–¼å„ªåŒ–å…§å­˜ä½¿ç”¨
            enable_cache: æ˜¯å¦å•Ÿç”¨æ¨¡å‹ç·©å­˜
        """
        try:
            # è‡ªå‹•æª¢æ¸¬è¨­å‚™ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
            if device is None:
                device = get_device()
            
            device_name_map = {
                'mps': 'MPS (macOS GPU)',
                'cuda': 'CUDA (NVIDIA GPU)',
                'cpu': 'CPU'
            }
            device_display = device_name_map.get(device, device)
            
            self.model = CrossEncoder(
                model_name, 
                device=device,
                max_length=max_length
            )
            self.max_length = max_length
            self.batch_size = batch_size
            self.model_name = model_name
            logger.info(f"âœ… é‡æ’æ¨¡å‹ {model_name} å·²è¼‰å…¥ (device: {device_display})")
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
            raise
    
    def _truncate_text(self, text: str, max_chars: int = 2000) -> str:
        """
        æˆªæ–·éé•·çš„æ–‡æœ¬ï¼ˆç²—ç•¥ä¼°è¨ˆï¼Œé¿å…è¶…é token é™åˆ¶ï¼‰
        
        Args:
            text: åŸå§‹æ–‡æœ¬
            max_chars: æœ€å¤§å­—ç¬¦æ•¸ï¼ˆä¿å®ˆä¼°è¨ˆï¼Œç´„ 500 tokensï¼‰
            
        Returns:
            æˆªæ–·å¾Œçš„æ–‡æœ¬
        """
        if len(text) <= max_chars:
            return text
        # æˆªæ–·ä¸¦æ·»åŠ çœç•¥è™Ÿ
        return text[:max_chars - 3] + "..."
    
    def _prepare_pairs(
        self, 
        query: str, 
        documents: List[Dict]
    ) -> List[Tuple[str, str]]:
        """
        æº–å‚™ (query, document) é…å°ï¼Œè™•ç†æ–‡æœ¬é•·åº¦
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            documents: æ–‡æª”åˆ—è¡¨
            
        Returns:
            (query, content) é…å°åˆ—è¡¨
        """
        pairs = []
        truncated_indices = []  # è¨˜éŒ„å“ªäº›æ–‡æª”è¢«æˆªæ–·äº†
        
        # ç²—ç•¥ä¼°è¨ˆï¼šæ¯å€‹å­—ç¬¦ç´„ 0.25 tokensï¼Œç‚º query é ç•™ç©ºé–“
        max_doc_chars = int((self.max_length * 0.7) - len(query))
        
        for i, doc in enumerate(documents):
            content = doc.get("content", "")
            original_length = len(content)
            
            # å¦‚æœå…§å®¹éé•·ï¼Œé€²è¡Œæˆªæ–·
            if len(content) > max_doc_chars:
                content = self._truncate_text(content, max_doc_chars)
                truncated_indices.append(i)
            
            pairs.append([query, content])
        
        if truncated_indices:
            logger.warning(
                f"âš ï¸  æœ‰ {len(truncated_indices)} å€‹æ–‡æª”å› éé•·è¢«æˆªæ–· "
                f"(æœ€å¤§é•·åº¦: {max_doc_chars} å­—ç¬¦)"
            )
        
        return pairs
    
    def rerank(
        self, 
        query: str, 
        documents: List[Dict], 
        top_k: int = 5,
        preserve_original_scores: bool = True
    ) -> List[Dict]:
        """
        åŸ·è¡Œç²¾æº–é‡æ’
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            documents: æ–‡æª”åˆ—è¡¨ï¼Œæ¯å€‹æ‡‰åŒ…å« "content" å’Œå¯é¸çš„ "hybrid_score"
            top_k: è¿”å›å‰ k å€‹çµæœ
            preserve_original_scores: æ˜¯å¦ä¿ç•™åŸå§‹åˆ†æ•¸ï¼ˆhybrid_scoreï¼‰
            
        Returns:
            é‡æ’å¾Œçš„æ–‡æª”åˆ—è¡¨ï¼ŒæŒ‰ rerank_score é™åºæ’åˆ—
        """
        if not documents:
            logger.warning("âš ï¸  æ–‡æª”åˆ—è¡¨ç‚ºç©ºï¼Œè¿”å›ç©ºçµæœ")
            return []
        
        if not query or not query.strip():
            logger.warning("âš ï¸  æŸ¥è©¢ç‚ºç©ºï¼Œè¿”å›åŸå§‹æ–‡æª”é †åº")
            return documents[:top_k]
        
        start_time = time.time()
        logger.info(f"ğŸ”„ é–‹å§‹é‡æ’ {len(documents)} å€‹æ–‡æª”...")
        
        try:
            # 1. æº–å‚™é…å°
            pairs = self._prepare_pairs(query, documents)
            
            # 2. æ‰¹è™•ç†è¨ˆç®—åˆ†æ•¸ï¼ˆå„ªåŒ–å…§å­˜ä½¿ç”¨ï¼‰
            scores = []
            for i in range(0, len(pairs), self.batch_size):
                batch_pairs = pairs[i:i + self.batch_size]
                batch_scores = self.model.predict(batch_pairs)
                scores.extend(batch_scores.tolist() if hasattr(batch_scores, 'tolist') else batch_scores)
            
            # 3. æ›´æ–°æ–‡æª”åˆ†æ•¸
            for i, doc in enumerate(documents):
                doc = doc.copy()  # é¿å…ä¿®æ”¹åŸå§‹æ–‡æª”
                doc["rerank_score"] = float(scores[i])
                
                # ä¿ç•™åŸå§‹åˆ†æ•¸ä¾›åƒè€ƒ
                if preserve_original_scores:
                    if "hybrid_score" not in doc:
                        # å¦‚æœæ²’æœ‰ hybrid_scoreï¼Œå˜—è©¦ä½¿ç”¨å…¶ä»–åˆ†æ•¸
                        doc["original_score"] = doc.get("score", 0.0)
                
                documents[i] = doc
            
            # 4. æ ¹æ“š rerank_score é‡æ–°æ’åº
            reranked_docs = sorted(
                documents, 
                key=lambda x: x.get("rerank_score", float('-inf')), 
                reverse=True
            )
            
            # 5. çµ±è¨ˆä¿¡æ¯
            elapsed_time = time.time() - start_time
            avg_score = sum(scores) / len(scores) if scores else 0.0
            max_score = max(scores) if scores else 0.0
            min_score = min(scores) if scores else 0.0
            
            logger.info(
                f"âœ… é‡æ’å®Œæˆ (è€—æ™‚: {elapsed_time:.2f}s, "
                f"å¹³å‡åˆ†æ•¸: {avg_score:.4f}, "
                f"ç¯„åœ: [{min_score:.4f}, {max_score:.4f}])"
            )
            
            return reranked_docs[:top_k]
            
        except Exception as e:
            logger.error(f"âŒ é‡æ’éç¨‹å‡ºéŒ¯: {e}")
            # é™ç´šç­–ç•¥ï¼šè¿”å›åŸå§‹é †åºçš„å‰ top_k å€‹
            logger.warning("âš ï¸  ä½¿ç”¨é™ç´šç­–ç•¥ï¼šè¿”å›åŸå§‹é †åº")
            return documents[:top_k]


class RAGPipeline:
    """å”èª¿ç®¡ç·šï¼šç®¡ç†å®Œæ•´çš„ RAG æµç¨‹ï¼ˆå¬å› + é‡æ’ï¼‰"""
    
    def __init__(
        self, 
        hybrid_search, 
        reranker, 
        recall_k: int = 25,
        adaptive_recall: bool = True,
        min_recall_k: int = 10,
        max_recall_k: int = 50
    ):
        """
        åˆå§‹åŒ– RAG ç®¡ç·š
        
        Args:
            hybrid_search: HybridSearch å¯¦ä¾‹
            reranker: Reranker å¯¦ä¾‹
            recall_k: ç¬¬ä¸€éšæ®µå¬å›çš„æ•¸é‡ï¼ˆé è¨­å€¼ï¼‰
            adaptive_recall: æ˜¯å¦æ ¹æ“šæŸ¥è©¢å‹•æ…‹èª¿æ•´ recall_k
            min_recall_k: æœ€å°å¬å›æ•¸é‡
            max_recall_k: æœ€å¤§å¬å›æ•¸é‡
        """
        self.hybrid_search = hybrid_search
        self.reranker = reranker
        self.base_recall_k = recall_k
        self.adaptive_recall = adaptive_recall
        self.min_recall_k = min_recall_k
        self.max_recall_k = max_recall_k
        
        # æ€§èƒ½çµ±è¨ˆ
        self.stats = {
            "total_queries": 0,
            "avg_recall_time": 0.0,
            "avg_rerank_time": 0.0,
            "avg_total_time": 0.0
        }
    
    def _calculate_adaptive_recall_k(self, query: str) -> int:
        """
        æ ¹æ“šæŸ¥è©¢è¤‡é›œåº¦å‹•æ…‹è¨ˆç®— recall_k
        
        Args:
            query: æŸ¥è©¢æ–‡æœ¬
            
        Returns:
            èª¿æ•´å¾Œçš„ recall_k
        """
        if not self.adaptive_recall:
            return self.base_recall_k
        
        # ç°¡å–®å•Ÿç™¼å¼ï¼šæ ¹æ“šæŸ¥è©¢é•·åº¦å’Œé—œéµè©æ•¸é‡èª¿æ•´
        query_length = len(query.split())
        keyword_count = len(set(query.lower().split()))
        
        # è¤‡é›œæŸ¥è©¢éœ€è¦æ›´å¤šå€™é¸
        if query_length > 10 or keyword_count > 5:
            recall_k = min(self.base_recall_k * 2, self.max_recall_k)
        elif query_length < 3:
            recall_k = max(self.base_recall_k // 2, self.min_recall_k)
        else:
            recall_k = self.base_recall_k
        
        return recall_k
    
    def query(
        self, 
        text: str, 
        top_k: int = 5, 
        metadata_filter: Optional[Dict] = None,
        enable_rerank: bool = True,
        return_stats: bool = False
    ) -> List[Dict]:
        """
        åŸ·è¡Œå®Œæ•´çš„æœå°‹æµç¨‹
        
        Args:
            text: æŸ¥è©¢æ–‡æœ¬
            top_k: æœ€çµ‚è¿”å›çš„çµæœæ•¸é‡
            metadata_filter: å¯é¸çš„ metadata éæ¿¾æ¢ä»¶
            enable_rerank: æ˜¯å¦å•Ÿç”¨é‡æ’åºï¼ˆå¯é¸ï¼Œç”¨æ–¼æ€§èƒ½æ¸¬è©¦ï¼‰
            return_stats: æ˜¯å¦è¿”å›æ€§èƒ½çµ±è¨ˆä¿¡æ¯
            
        Returns:
            ç›¸é—œæ–‡æª”åˆ—è¡¨ï¼Œå¦‚æœ return_stats=Trueï¼Œå‰‡è¿”å› (results, stats) å…ƒçµ„
        """
        if not text or not text.strip():
            logger.warning("âš ï¸  æŸ¥è©¢ç‚ºç©º")
            return []
        
        total_start = time.time()
        self.stats["total_queries"] += 1
        
        # å‹•æ…‹è¨ˆç®— recall_k
        recall_k = self._calculate_adaptive_recall_k(text)
        logger.info(
            f"ğŸ” æœå°‹ä¸­: '{text[:50]}...' "
            f"(å¬å›éšæ®µ: {recall_k} ç­†, æœ€çµ‚è¿”å›: {top_k} ç­†)"
        )
        
        try:
            # ç¬¬ä¸€éšæ®µï¼šæ··åˆæœå°‹ï¼ˆå¬å›éšæ®µï¼‰
            recall_start = time.time()
            initial_results = self.hybrid_search.retrieve(
                query=text, 
                top_k=recall_k, 
                metadata_filter=metadata_filter
            )
            recall_time = time.time() - recall_start
            
            if not initial_results:
                logger.warning("âš ï¸  å¬å›éšæ®µæœªæ‰¾åˆ°ä»»ä½•çµæœ")
                return []
            
            logger.info(
                f"âœ… å¬å›éšæ®µå®Œæˆ: æ‰¾åˆ° {len(initial_results)} å€‹å€™é¸ "
                f"(è€—æ™‚: {recall_time:.2f}s)"
            )
            
            # ç¬¬äºŒéšæ®µï¼šé‡æ’åºï¼ˆç²¾ç¯©éšæ®µï¼‰
            if enable_rerank and len(initial_results) > top_k:
                rerank_start = time.time()
                final_results = self.reranker.rerank(
                    query=text, 
                    documents=initial_results, 
                    top_k=top_k
                )
                rerank_time = time.time() - rerank_start
                
                logger.info(
                    f"âœ… é‡æ’éšæ®µå®Œæˆ: å¾ {len(initial_results)} å€‹å€™é¸ä¸­é¸å‡º "
                    f"{len(final_results)} å€‹çµæœ (è€—æ™‚: {rerank_time:.2f}s)"
                )
            else:
                # è·³éé‡æ’åºï¼ˆç”¨æ–¼æ€§èƒ½æ¸¬è©¦æˆ–å€™é¸æ•¸è¼ƒå°‘æ™‚ï¼‰
                final_results = initial_results[:top_k]
                rerank_time = 0.0
                logger.info("â­ï¸  è·³éé‡æ’åºéšæ®µï¼ˆå€™é¸æ•¸ä¸è¶³æˆ–å·²ç¦ç”¨ï¼‰")
            
            # æ›´æ–°çµ±è¨ˆä¿¡æ¯
            total_time = time.time() - total_start
            self._update_stats(recall_time, rerank_time, total_time)
            
            # æ·»åŠ æ€§èƒ½ä¿¡æ¯åˆ°çµæœï¼ˆå¯é¸ï¼‰
            if return_stats:
                stats = {
                    "recall_time": recall_time,
                    "rerank_time": rerank_time,
                    "total_time": total_time,
                    "recall_k": recall_k,
                    "candidates_found": len(initial_results),
                    "final_results": len(final_results)
                }
                return final_results, stats
            
            return final_results
            
        except Exception as e:
            logger.error(f"âŒ æŸ¥è©¢éç¨‹å‡ºéŒ¯: {e}")
            # é™ç´šç­–ç•¥ï¼šå˜—è©¦åªä½¿ç”¨å¬å›éšæ®µ
            try:
                logger.warning("âš ï¸  å˜—è©¦é™ç´šç­–ç•¥ï¼šåƒ…ä½¿ç”¨å¬å›çµæœ")
                return self.hybrid_search.retrieve(text, top_k=top_k, metadata_filter=metadata_filter)
            except Exception as e2:
                logger.error(f"âŒ é™ç´šç­–ç•¥ä¹Ÿå¤±æ•—: {e2}")
                return []
    
    def _update_stats(self, recall_time: float, rerank_time: float, total_time: float):
        """æ›´æ–°æ€§èƒ½çµ±è¨ˆä¿¡æ¯"""
        n = self.stats["total_queries"]
        self.stats["avg_recall_time"] = (
            (self.stats["avg_recall_time"] * (n - 1) + recall_time) / n
        )
        self.stats["avg_rerank_time"] = (
            (self.stats["avg_rerank_time"] * (n - 1) + rerank_time) / n
        )
        self.stats["avg_total_time"] = (
            (self.stats["avg_total_time"] * (n - 1) + total_time) / n
        )
    
    def get_stats(self) -> Dict:
        """ç²å–æ€§èƒ½çµ±è¨ˆä¿¡æ¯"""
        return self.stats.copy()
    
    def reset_stats(self):
        """é‡ç½®çµ±è¨ˆä¿¡æ¯"""
        self.stats = {
            "total_queries": 0,
            "avg_recall_time": 0.0,
            "avg_rerank_time": 0.0,
            "avg_total_time": 0.0
        }
    
    def format_results_for_llm(
        self,
        results: List[Dict],
        format_style: str = "detailed"
    ) -> str:
        """
        æ ¼å¼åŒ–æª¢ç´¢çµæœä¾› LLM ä½¿ç”¨ï¼ˆéœ€è¦å°å…¥ PromptFormatterï¼‰
        
        Args:
            results: æª¢ç´¢çµæœåˆ—è¡¨
            format_style: æ ¼å¼é¢¨æ ¼ ("detailed", "simple", "minimal")
            
        Returns:
            æ ¼å¼åŒ–å¾Œçš„ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        try:
            from ..prompt_formatter import PromptFormatter
            formatter = PromptFormatter(format_style=format_style)
            return formatter.format_context(results)
        except ImportError:
            # å¦‚æœç„¡æ³•å°å…¥ï¼Œä½¿ç”¨ç°¡å–®æ ¼å¼
            formatted_parts = []
            for i, result in enumerate(results, 1):
                metadata = result.get("metadata", {})
                content = result.get("content", "")
                arxiv_id = metadata.get('arxiv_id', 'N/A')
                title = metadata.get('title', 'N/A')
                formatted_parts.append(
                    f"[ä¾†æº {i}: {title} (arXiv:{arxiv_id})]\n{content}\n"
                )
            return "\n" + "="*60 + "\n".join(formatted_parts)

