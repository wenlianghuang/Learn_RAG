"""
Sub-query Decomposition RAGï¼šå°‡è¤‡é›œå•é¡Œæ‹†è§£æˆå­å•é¡Œå¾Œæª¢ç´¢
"""
from typing import List, Dict, Optional
from .retrievers.reranker import RAGPipeline
from .prompt_formatter import PromptFormatter
from .llm_integration import OllamaLLM
import hashlib
import time
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed

logger = logging.getLogger(__name__)


class SubQueryDecompositionRAG:
    """ä½¿ç”¨å­å•é¡Œæ‹†è§£çš„ RAG ç³»çµ±"""
    
    def __init__(
        self,
        rag_pipeline: RAGPipeline,
        llm: OllamaLLM,
        max_sub_queries: int = 3,
        top_k_per_subquery: int = 5,
        enable_parallel: bool = True
    ):
        """
        åˆå§‹åŒ– Sub-query Decomposition RAG
        
        Args:
            rag_pipeline: ç¾æœ‰çš„ RAG ç®¡ç·šå¯¦ä¾‹
            llm: LLM å¯¦ä¾‹ï¼ˆç”¨æ–¼ç”Ÿæˆå­å•é¡Œï¼‰
            max_sub_queries: æœ€å¤šç”Ÿæˆçš„å­å•é¡Œæ•¸é‡
            top_k_per_subquery: æ¯å€‹å­å•é¡Œæª¢ç´¢çš„çµæœæ•¸é‡
            enable_parallel: æ˜¯å¦ä¸¦è¡Œè™•ç†å­æŸ¥è©¢
        """
        self.rag_pipeline = rag_pipeline
        self.llm = llm
        self.max_sub_queries = max_sub_queries
        self.top_k_per_subquery = top_k_per_subquery
        self.enable_parallel = enable_parallel
    
    def _generate_sub_queries(self, question: str) -> List[str]:
        """
        å°‡åŸå§‹å•é¡Œæ‹†è§£æˆå­å•é¡Œ
        
        Args:
            question: åŸå§‹å•é¡Œ
            
        Returns:
            å­å•é¡Œåˆ—è¡¨
        """
        # æª¢æ¸¬èªè¨€
        is_chinese = PromptFormatter.detect_language(question) == "zh"
        
        if is_chinese:
            prompt = f"""ä½ æ˜¯ä¸€å€‹å°ˆæ¥­åŠ©ç†ã€‚è«‹å°‡ä»¥ä¸‹åŸå§‹å•é¡Œæ‹†è§£æˆæœ€å¤š {self.max_sub_queries} å€‹å…·é«”çš„å­å•é¡Œï¼Œä»¥ä¾¿é€²è¡Œè³‡æ–™æœå°‹ã€‚
æ¯å€‹å­å•é¡Œæ‡‰å°ˆæ³¨æ–¼åŸå§‹å•é¡Œçš„ä¸€å€‹ç‰¹å®šé¢å‘ã€‚è«‹ä»¥æ›è¡Œç¬¦è™Ÿåˆ†éš”å•é¡Œã€‚

åŸå§‹å•é¡Œ: {question}

å­å•é¡Œæ¸…å–®:"""
        else:
            prompt = f"""You are a professional assistant. Please decompose the following original question into at most {self.max_sub_queries} specific sub-questions for information retrieval.
Each sub-question should focus on a specific aspect of the original question. Please separate questions with newlines.

Original question: {question}

Sub-question list:"""
        
        try:
            response = self.llm.generate(
                prompt=prompt,
                temperature=0.3,  # é™ä½æº«åº¦ä»¥ç²å¾—æ›´ç©©å®šçš„çµæœ
                max_tokens=500
            )
            
            # è§£æå­å•é¡Œ
            sub_queries = [
                q.strip() 
                for q in response.strip().split("\n") 
                if q.strip() and not q.strip().startswith("#")
            ]
            
            # ç§»é™¤ç·¨è™Ÿå‰ç¶´ï¼ˆå¦‚ "1. ", "1) " ç­‰ï¼‰
            cleaned_queries = []
            for q in sub_queries:
                # ç§»é™¤é–‹é ­çš„ç·¨è™Ÿ
                q = q.lstrip("0123456789. )")
                q = q.strip()
                if q:
                    cleaned_queries.append(q)
            
            # é™åˆ¶æ•¸é‡
            cleaned_queries = cleaned_queries[:self.max_sub_queries]
            
            # å¦‚æœæ²’æœ‰ç”Ÿæˆå­å•é¡Œï¼Œä½¿ç”¨åŸå§‹å•é¡Œ
            if not cleaned_queries:
                logger.warning("âš ï¸  æœªç”Ÿæˆå­å•é¡Œï¼Œä½¿ç”¨åŸå§‹å•é¡Œ")
                cleaned_queries = [question]
            
            return cleaned_queries
            
        except Exception as e:
            logger.error(f"âš ï¸  ç”Ÿæˆå­å•é¡Œæ™‚å‡ºéŒ¯: {e}")
            # å›é€€åˆ°åŸå§‹å•é¡Œ
            return [question]
    
    def _get_doc_id(self, doc: Dict) -> str:
        """
        ç”Ÿæˆæ–‡æª”çš„å”¯ä¸€æ¨™è­˜ç¬¦
        
        Args:
            doc: æ–‡æª”å­—å…¸
            
        Returns:
            å”¯ä¸€ ID
        """
        metadata = doc.get("metadata", {})
        content = doc.get("content", "")
        
        # ä½¿ç”¨ metadata ä¸­çš„å”¯ä¸€æ¨™è­˜ï¼ˆå¦‚æœæœ‰çš„è©±ï¼‰
        if "arxiv_id" in metadata and "chunk_index" in metadata:
            return f"{metadata['arxiv_id']}_{metadata['chunk_index']}"
        elif "file_path" in metadata and "chunk_index" in metadata:
            return f"{metadata['file_path']}_{metadata['chunk_index']}"
        else:
            # å›é€€åˆ°å…§å®¹çš„ hash
            content_hash = hashlib.md5(content.encode()).hexdigest()[:16]
            return f"doc_{content_hash}"
    
    def _retrieve_for_subquery(
        self, 
        sub_query: str, 
        metadata_filter: Optional[Dict] = None
    ) -> List[Dict]:
        """
        é‡å°å–®å€‹å­å•é¡Œé€²è¡Œæª¢ç´¢
        
        Args:
            sub_query: å­å•é¡Œ
            metadata_filter: å¯é¸çš„ metadata éæ¿¾æ¢ä»¶
            
        Returns:
            æª¢ç´¢çµæœåˆ—è¡¨
        """
        try:
            results = self.rag_pipeline.query(
                text=sub_query,
                top_k=self.top_k_per_subquery,
                metadata_filter=metadata_filter,
                enable_rerank=True
            )
            return results
        except Exception as e:
            logger.error(f"âš ï¸  æª¢ç´¢å­å•é¡Œ '{sub_query}' æ™‚å‡ºéŒ¯: {e}")
            return []
    
    def _get_unique_documents(
        self, 
        sub_queries: List[str],
        metadata_filter: Optional[Dict] = None
    ) -> List[Dict]:
        """
        é‡å°æ‰€æœ‰å­å•é¡Œé€²è¡Œæª¢ç´¢ï¼Œä¸¦ç§»é™¤é‡è¤‡çš„æ–‡ä»¶
        
        Args:
            sub_queries: å­å•é¡Œåˆ—è¡¨
            metadata_filter: å¯é¸çš„ metadata éæ¿¾æ¢ä»¶
            
        Returns:
            å»é‡å¾Œçš„æ–‡æª”åˆ—è¡¨
        """
        unique_docs = {}
        
        if self.enable_parallel and len(sub_queries) > 1:
            # ä¸¦è¡Œè™•ç†å­æŸ¥è©¢
            logger.info(f"ğŸ”„ ä¸¦è¡Œè™•ç† {len(sub_queries)} å€‹å­æŸ¥è©¢...")
            with ThreadPoolExecutor(max_workers=min(len(sub_queries), 5)) as executor:
                future_to_query = {
                    executor.submit(self._retrieve_for_subquery, q, metadata_filter): q
                    for q in sub_queries
                }
                
                for future in as_completed(future_to_query):
                    sub_query = future_to_query[future]
                    try:
                        docs = future.result()
                        logger.debug(f"âœ… å­å•é¡Œ '{sub_query}' æ‰¾åˆ° {len(docs)} å€‹çµæœ")
                        for doc in docs:
                            doc_id = self._get_doc_id(doc)
                            if doc_id not in unique_docs:
                                unique_docs[doc_id] = doc
                            else:
                                # å¦‚æœå·²å­˜åœ¨ï¼Œä¿ç•™åˆ†æ•¸æ›´é«˜çš„
                                existing_score = unique_docs[doc_id].get(
                                    'rerank_score', 
                                    unique_docs[doc_id].get('hybrid_score', 0)
                                )
                                new_score = doc.get(
                                    'rerank_score',
                                    doc.get('hybrid_score', 0)
                                )
                                if new_score > existing_score:
                                    unique_docs[doc_id] = doc
                    except Exception as e:
                        logger.error(f"âš ï¸  è™•ç†å­å•é¡Œ '{sub_query}' æ™‚å‡ºéŒ¯: {e}")
        else:
            # ä¸²è¡Œè™•ç†
            logger.info(f"ğŸ”„ ä¸²è¡Œè™•ç† {len(sub_queries)} å€‹å­æŸ¥è©¢...")
            for sub_query in sub_queries:
                docs = self._retrieve_for_subquery(sub_query, metadata_filter)
                logger.debug(f"âœ… å­å•é¡Œ '{sub_query}' æ‰¾åˆ° {len(docs)} å€‹çµæœ")
                for doc in docs:
                    doc_id = self._get_doc_id(doc)
                    if doc_id not in unique_docs:
                        unique_docs[doc_id] = doc
                    else:
                        # ä¿ç•™åˆ†æ•¸æ›´é«˜çš„
                        existing_score = unique_docs[doc_id].get(
                            'rerank_score',
                            unique_docs[doc_id].get('hybrid_score', 0)
                        )
                        new_score = doc.get(
                            'rerank_score',
                            doc.get('hybrid_score', 0)
                        )
                        if new_score > existing_score:
                            unique_docs[doc_id] = doc
        
        # æŒ‰åˆ†æ•¸æ’åº
        result_list = list(unique_docs.values())
        result_list.sort(
            key=lambda x: x.get('rerank_score', x.get('hybrid_score', 0)),
            reverse=True
        )
        
        return result_list
    
    def query(
        self,
        question: str,
        top_k: int = 5,
        metadata_filter: Optional[Dict] = None,
        return_sub_queries: bool = False
    ) -> Dict:
        """
        åŸ·è¡Œ Sub-query Decomposition RAG æŸ¥è©¢
        
        Args:
            question: åŸå§‹å•é¡Œ
            top_k: è¿”å›å‰ k å€‹çµæœ
            metadata_filter: å¯é¸çš„ metadata éæ¿¾æ¢ä»¶
            return_sub_queries: æ˜¯å¦åœ¨çµæœä¸­åŒ…å«å­å•é¡Œåˆ—è¡¨
            
        Returns:
            åŒ…å«æª¢ç´¢çµæœå’Œçµ±è¨ˆä¿¡æ¯çš„å­—å…¸
        """
        start_time = time.time()
        
        # ç¬¬ä¸€æ­¥ï¼šç”¢ç”Ÿå­å•é¡Œ
        logger.info(f"ğŸ” æ‹†è§£å•é¡Œ: '{question}'")
        sub_queries = self._generate_sub_queries(question)
        logger.info(f"âœ… ç”Ÿæˆ {len(sub_queries)} å€‹å­å•é¡Œ:")
        for i, sq in enumerate(sub_queries, 1):
            logger.info(f"   {i}. {sq}")
        
        # ç¬¬äºŒæ­¥ï¼šæª¢ç´¢ä¸¦å»é‡
        logger.info(f"ğŸ“š æª¢ç´¢ç›¸é—œæ–‡æª”...")
        docs = self._get_unique_documents(sub_queries, metadata_filter)
        logger.info(f"âœ… æ‰¾åˆ° {len(docs)} å€‹å”¯ä¸€æ–‡æª”ï¼ˆå»é‡å¾Œï¼‰")
        
        # ç¬¬ä¸‰æ­¥ï¼šè¿”å›å‰ top_k å€‹çµæœ
        final_results = docs[:top_k]
        
        elapsed_time = time.time() - start_time
        
        result = {
            "results": final_results,
            "total_docs_found": len(docs),
            "sub_queries": sub_queries if return_sub_queries else None,
            "elapsed_time": elapsed_time
        }
        
        return result
    
    def generate_answer(
        self,
        question: str,
        formatter: PromptFormatter,
        top_k: int = 5,
        metadata_filter: Optional[Dict] = None,
        document_type: str = "general",
        return_sub_queries: bool = False
    ) -> Dict:
        """
        å®Œæ•´çš„ Sub-query Decomposition RAG æµç¨‹ï¼šæª¢ç´¢ + ç”Ÿæˆç­”æ¡ˆ
        
        Args:
            question: åŸå§‹å•é¡Œ
            formatter: Prompt æ ¼å¼åŒ–å™¨
            top_k: è¿”å›å‰ k å€‹çµæœç”¨æ–¼ç”Ÿæˆç­”æ¡ˆ
            metadata_filter: å¯é¸çš„ metadata éæ¿¾æ¢ä»¶
            document_type: æ–‡æª”é¡å‹ ("paper", "cv", "general")
            return_sub_queries: æ˜¯å¦åœ¨çµæœä¸­åŒ…å«å­å•é¡Œåˆ—è¡¨
            
        Returns:
            åŒ…å«æª¢ç´¢çµæœã€ç”Ÿæˆçš„ç­”æ¡ˆå’Œçµ±è¨ˆä¿¡æ¯çš„å­—å…¸
        """
        # æª¢ç´¢
        retrieval_result = self.query(
            question=question,
            top_k=top_k,
            metadata_filter=metadata_filter,
            return_sub_queries=return_sub_queries
        )
        
        if not retrieval_result["results"]:
            return {
                **retrieval_result,
                "answer": "æŠ±æ­‰ï¼Œæœªæ‰¾åˆ°ç›¸é—œæ–‡æª”ä¾†å›ç­”æ­¤å•é¡Œã€‚",
                "formatted_context": None
            }
        
        # æ ¼å¼åŒ–ä¸Šä¸‹æ–‡
        formatted_context = formatter.format_context(
            retrieval_result["results"],
            document_type=document_type
        )
        
        # å‰µå»º prompt
        prompt = formatter.create_prompt(
            question,
            formatted_context,
            document_type=document_type
        )
        
        # ç”Ÿæˆå›ç­”
        logger.info("ğŸ¤– ç”Ÿæˆå›ç­”ä¸­...")
        answer_start = time.time()
        try:
            answer = self.llm.generate(
                prompt=prompt,
                temperature=0.7,
                max_tokens=2048
            )
            answer_time = time.time() - answer_start
            logger.info(f"âœ… å›ç­”ç”Ÿæˆå®Œæˆï¼ˆè€—æ™‚: {answer_time:.2f}sï¼‰")
        except Exception as e:
            logger.error(f"âŒ ç”Ÿæˆå›ç­”æ™‚å‡ºéŒ¯: {e}")
            answer = f"ç”Ÿæˆå›ç­”æ™‚å‡ºéŒ¯: {e}"
            answer_time = time.time() - answer_start
        
        return {
            **retrieval_result,
            "answer": answer,
            "formatted_context": formatted_context,
            "answer_time": answer_time,
            "total_time": retrieval_result["elapsed_time"] + answer_time
        }

